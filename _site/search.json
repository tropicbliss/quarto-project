[
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "Geospatial analytics offer valuable insights into the patterns of armed conflict, enabling better understanding and response strategies. This study focuses on armed conflict events in Myanmar from January 2021 to June 2024, using data from the Armed Conflict Location & Event Data (ACLED) project. The analysis examines the spatial and temporal distribution of four key event types: Battles, Explosion/Remote Violence, Strategic Developments, and Violence Against Civilians. By investigating quarterly data, this study aims to reveal patterns in the conflict, contributing to a deeper understanding of the ongoing violence in Myanmar.\nTo start off, let’s begin by importing all the necessary libraries:\npacman::p_load(sf, tidyverse, tmap, spatstat, raster)\nNow that we have done so, let’s load the necessary combat data from ACLED (note that due to API limitations I am only able to get data from a certain starting date):\nconflict_data &lt;- read_csv(\"data/2021-08-31-2024-06-30-Myanmar.csv\")\n\nRows: 41275 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): event_id_cnty, event_date, disorder_type, event_type, sub_event_ty...\ndbl (11): year, time_precision, inter1, inter2, interaction, iso, latitude, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nlist(conflict_data)\n\n[[1]]\n# A tibble: 41,275 × 31\n   event_id_cnty event_date    year time_precision disorder_type      event_type\n   &lt;chr&gt;         &lt;chr&gt;        &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;              &lt;chr&gt;     \n 1 MMR64313      30 June 2024  2024              1 Political violence Battles   \n 2 MMR64320      30 June 2024  2024              1 Political violence Battles   \n 3 MMR64321      30 June 2024  2024              1 Political violence Battles   \n 4 MMR64322      30 June 2024  2024              1 Strategic develop… Strategic…\n 5 MMR64323      30 June 2024  2024              1 Political violence Battles   \n 6 MMR64324      30 June 2024  2024              1 Strategic develop… Strategic…\n 7 MMR64325      30 June 2024  2024              1 Political violence Battles   \n 8 MMR64326      30 June 2024  2024              1 Political violence Battles   \n 9 MMR64328      30 June 2024  2024              1 Political violence Battles   \n10 MMR64330      30 June 2024  2024              1 Political violence Battles   \n# ℹ 41,265 more rows\n# ℹ 25 more variables: sub_event_type &lt;chr&gt;, actor1 &lt;chr&gt;, assoc_actor_1 &lt;chr&gt;,\n#   inter1 &lt;dbl&gt;, actor2 &lt;chr&gt;, assoc_actor_2 &lt;chr&gt;, inter2 &lt;dbl&gt;,\n#   interaction &lt;dbl&gt;, civilian_targeting &lt;chr&gt;, iso &lt;dbl&gt;, region &lt;chr&gt;,\n#   country &lt;chr&gt;, admin1 &lt;chr&gt;, admin2 &lt;chr&gt;, admin3 &lt;chr&gt;, location &lt;chr&gt;,\n#   latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, geo_precision &lt;dbl&gt;, source &lt;chr&gt;,\n#   source_scale &lt;chr&gt;, notes &lt;chr&gt;, fatalities &lt;dbl&gt;, tags &lt;chr&gt;, …\nWe have the latitude and longitude of event locations. We need to convert them into SFOs such that we can work with them using the sf library. Additionally, we need to normalise the dates such that they are all standardised into the same format that is computer readable.\nconflict_data &lt;- conflict_data %&gt;% st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;% st_transform(crs = 32647) %&gt;% mutate(event_date = dmy(event_date))\nlist(conflict_data)\n\n[[1]]\nSimple feature collection with 41275 features and 29 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -208804.4 ymin: 1103500 xmax: 640934.5 ymax: 3042960\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 41,275 × 30\n   event_id_cnty event_date  year time_precision disorder_type        event_type\n * &lt;chr&gt;         &lt;date&gt;     &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;                &lt;chr&gt;     \n 1 MMR64313      2024-06-30  2024              1 Political violence   Battles   \n 2 MMR64320      2024-06-30  2024              1 Political violence   Battles   \n 3 MMR64321      2024-06-30  2024              1 Political violence   Battles   \n 4 MMR64322      2024-06-30  2024              1 Strategic developme… Strategic…\n 5 MMR64323      2024-06-30  2024              1 Political violence   Battles   \n 6 MMR64324      2024-06-30  2024              1 Strategic developme… Strategic…\n 7 MMR64325      2024-06-30  2024              1 Political violence   Battles   \n 8 MMR64326      2024-06-30  2024              1 Political violence   Battles   \n 9 MMR64328      2024-06-30  2024              1 Political violence   Battles   \n10 MMR64330      2024-06-30  2024              1 Political violence   Battles   \n# ℹ 41,265 more rows\n# ℹ 24 more variables: sub_event_type &lt;chr&gt;, actor1 &lt;chr&gt;, assoc_actor_1 &lt;chr&gt;,\n#   inter1 &lt;dbl&gt;, actor2 &lt;chr&gt;, assoc_actor_2 &lt;chr&gt;, inter2 &lt;dbl&gt;,\n#   interaction &lt;dbl&gt;, civilian_targeting &lt;chr&gt;, iso &lt;dbl&gt;, region &lt;chr&gt;,\n#   country &lt;chr&gt;, admin1 &lt;chr&gt;, admin2 &lt;chr&gt;, admin3 &lt;chr&gt;, location &lt;chr&gt;,\n#   geo_precision &lt;dbl&gt;, source &lt;chr&gt;, source_scale &lt;chr&gt;, notes &lt;chr&gt;,\n#   fatalities &lt;dbl&gt;, tags &lt;chr&gt;, timestamp &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\nNow that we have the armed conflict data, let’s import the administrative boundary data:\nboundaries &lt;- st_read(\"data\", layer = \"mmr_polbnda2_adm1_250k_mimu_1\")\n\nReading layer `mmr_polbnda2_adm1_250k_mimu_1' from data source \n  `/home/tropicbliss/GitHub/quarto-project/Take-home_Ex/Take-home_Ex01/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 18 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\nst_crs(boundaries)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\nThis is currently in WGS84, and we need to convert it into a projected coordinate system so we can work with the data.\nboundaries &lt;- boundaries %&gt;% st_transform(crs = 32647)\nst_crs(boundaries)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            MEMBER[\"World Geodetic System 1984 (G2296)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\nA horrifying amount, most of which seems to be clustered at the interior of Myanmar. Let’s overlay an administrative district map to see where most of them are all located at:\ntmap_mode('plot')\n\nℹ tmap mode set to \"plot\".\n\nmap1 &lt;- tm_shape(boundaries) +\n  tm_fill() +\n  tm_borders() +\n  tm_text(\"ST\", size = 0.2, col = \"blue\")\nmap2 &lt;- tm_shape(boundaries) +\n  tm_fill() +\n  tm_borders() +\n  tm_shape(conflict_data) +\n  tm_dots()\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#quarterly-kde-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#quarterly-kde-analysis",
    "title": "Take Home Exercise 1",
    "section": "Quarterly KDE analysis",
    "text": "Quarterly KDE analysis\nNow we are going to apply Kernel Density Estimation (KDE) to conflict events for each quarter of the year. These layers show the density of events over a geographic area, which can help visualize how the concentration of those events changes over time, particularly on a quarterly basis. However, to do that we need to choose an appropriate year to observe the by-quarterly results. After much deliberation I have chose 2022 as the best year for this, and here’s why:\n\nThe coup started in February 2021. While it might be interesting to analyse the slow growth in conflicts over time, the data is not representative of the Myanmar conflict as a whole.\nIn 2022, the political and military landscape had largely stabilized after the initial shock of the coup in 2021. The armed resistance led by various ethnic armed organizations (EAOs) and the People’s Defense Forces (PDFs) was more organized and widespread.\n\n\nData extraction and filtering\nExtracting conflict data by quarter:\n\nconflict_data_2022_q1 &lt;- conflict_data %&gt;% filter(event_date &gt;= as.Date(\"2022-01-01\") & event_date &lt;= as.Date(\"2022-03-31\"))\nconflict_data_2022_q2 &lt;- conflict_data %&gt;% filter(event_date &gt;= as.Date(\"2022-04-01\") & event_date &lt;= as.Date(\"2022-06-30\"))\nconflict_data_2022_q3 &lt;- conflict_data %&gt;% filter(event_date &gt;= as.Date(\"2022-07-01\") & event_date &lt;= as.Date(\"2022-09-30\"))\nconflict_data_2022_q4 &lt;- conflict_data %&gt;% filter(event_date &gt;= as.Date(\"2022-10-01\") & event_date &lt;= as.Date(\"2022-12-31\"))\n\n\n\nData conversion\n::: {.callout-note}\nThe bandwidth in the context of KDE is a critical parameter that determines the level of smoothing applied to the data when estimating the density. It controls how much each data point influences the estimate of the density around it.\n:::\n\nconflict_data_2022_q1_ppp &lt;- as.ppp(conflict_data_2022_q1)\n\nWarning in as.ppp.sf(conflict_data_2022_q1): only first attribute column is\nused for marks\n\nconflict_data_2022_q2_ppp &lt;- as.ppp(conflict_data_2022_q2)\n\nWarning in as.ppp.sf(conflict_data_2022_q2): only first attribute column is\nused for marks\n\nconflict_data_2022_q3_ppp &lt;- as.ppp(conflict_data_2022_q3)\n\nWarning in as.ppp.sf(conflict_data_2022_q3): only first attribute column is\nused for marks\n\nconflict_data_2022_q4_ppp &lt;- as.ppp(conflict_data_2022_q4)\n\nWarning in as.ppp.sf(conflict_data_2022_q4): only first attribute column is\nused for marks\n\n\n\nplot(conflict_data_2022_q1_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 4267 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\nsummary(conflict_data_2022_q1_ppp)\n\nMarked planar point pattern:  4267 points\nAverage intensity 2.785283e-09 points per square unit\n\nCoordinates are given to 13 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     4267 character character \n\nWindow: rectangle = [-204784, 591875.9] x [1103500.1, 3026504.9] units\n                    (796700 x 1923000 units)\nWindow area = 1.53198e+12 square units\n\n\nMany statistical methods in spatial point pattern analysis are based on the assumption that the underlying point process is simple. A simple point process means that no two points in the process can occupy the exact same location (i.e., they cannot be coincident).\nIf points are coincident, this assumption is violated, and the statistical methods that rely on this assumption may produce invalid or misleading results.\nThus, let’s check if there are any duplicate points:\n\nany(duplicated(conflict_data_2022_q1_ppp))\n\n[1] FALSE\n\nany(duplicated(conflict_data_2022_q2_ppp))\n\n[1] FALSE\n\nany(duplicated(conflict_data_2022_q3_ppp))\n\n[1] FALSE\n\nany(duplicated(conflict_data_2022_q4_ppp))\n\n[1] FALSE\n\n\nAs you can see, there doesn’t seem to be any duplicated data points.\nNext, we need to create an owin object. This helps to confine the analysis within a specific geographical area.\n\nboundaries_owin &lt;- as.owin(boundaries)\n\n\nplot(boundaries_owin)\n\n\n\n\n\n\n\n\nAs, you can see, the owin object contains state boundaries, which we don’t need. We need to find a way to dissolve those state boundaries.\n\nmyanmar_sf &lt;- st_union(boundaries)\n\n\nplot(myanmar_sf)\n\n\n\n\n\n\n\n\nStill not that good. Luckily the website also contain geographical data that does not include state lines.\n\nnational_boundaries &lt;- st_read(\"data\", layer = \"mmr_polbnda_adm0_250k_mimu_1\") %&gt;% st_transform(crs = 32647)\n\nReading layer `mmr_polbnda_adm0_250k_mimu_1' from data source \n  `/home/tropicbliss/GitHub/quarto-project/Take-home_Ex/Take-home_Ex01/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nst_crs(boundaries)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            MEMBER[\"World Geodetic System 1984 (G2296)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\nnational_boundaries_owin &lt;- as.owin(national_boundaries)\n\n\nplot(national_boundaries_owin)\n\n\n\n\n\n\n\n\nThat’s much better. We simply need to combine the ppp and the owin objects.\n\nconflictMYQ1_ppp &lt;- conflict_data_2022_q1_ppp[national_boundaries_owin]\nconflictMYQ2_ppp &lt;- conflict_data_2022_q2_ppp[national_boundaries_owin]\nconflictMYQ3_ppp &lt;- conflict_data_2022_q3_ppp[national_boundaries_owin]\nconflictMYQ4_ppp &lt;- conflict_data_2022_q4_ppp[national_boundaries_owin]\n\n\nplot(conflictMYQ1_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 4267 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\ncrs_info &lt;- st_crs(national_boundaries)\nunit_of_measurement &lt;- crs_info$units\nprint(unit_of_measurement)\n\n[1] \"m\"\n\n\nFirst, we need to convert the unit of measurement to kilometres since the density values would be too small to comprehend.\n\nconflictMYQ1_ppp.km &lt;- rescale.ppp(conflictMYQ1_ppp, 1000, \"km\")\nconflictMYQ2_ppp.km &lt;- rescale.ppp(conflictMYQ2_ppp, 1000, \"km\")\nconflictMYQ3_ppp.km &lt;- rescale.ppp(conflictMYQ3_ppp, 1000, \"km\")\nconflictMYQ4_ppp.km &lt;- rescale.ppp(conflictMYQ4_ppp, 1000, \"km\")\n\n\n\nWorking with different bandwidth methods\n\nbw.CvL(conflictMYQ1_ppp.km)\n\n   sigma \n66.96841 \n\n\n\nbw.scott(conflictMYQ1_ppp.km)\n\n sigma.x  sigma.y \n33.58016 77.84496 \n\n\n\nbw.ppl(conflictMYQ1_ppp.km)\n\n   sigma \n4.298156 \n\n\n\nbw.diggle(conflictMYQ1_ppp.km)\n\n    sigma \n0.2187043 \n\n\nThe sigma values for bw.diggle and bw.ppl seem way too small. A small sigma value might result in sudden spikes of the data over an extremely small area, which would not be useful when analysing such a large geographical area. Since the conflict data contains regions where points seem to be highly clustered, an automatic bandwidth selection method might select a smaller sigma to capture the fine structure in those areas. This can lead to undersmoothing across the entire dataset, making the density plot appear as many small bright spots with abrupt transitions.\n\nkde_conflictMYQ1_scott &lt;- density(conflictMYQ1_ppp.km, sigma=bw.scott, edge=TRUE, kernel=\"quartic\")\n\nWarning in density.ppp(conflictMYQ1_ppp.km, sigma = bw.scott, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nkde_conflictMYQ1_CvL &lt;- density(conflictMYQ1_ppp.km, sigma=bw.scott, edge=TRUE, kernel=\"quartic\")\n\nWarning in density.ppp(conflictMYQ1_ppp.km, sigma = bw.scott, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\npar(mfrow=c(1,2))\nplot(kde_conflictMYQ1_scott, main = \"bw.scott\")\nplot(kde_conflictMYQ1_CvL, main = \"bw.CvL\")\n\n\n\n\n\n\n\n\nFrom trial and error, it seems like bw.scott is the best fit for our use case.\nThe edge parameter controls whether edge correction should be applied. Edge correction accounts for the fact that points near the boundaries of the observation window have fewer neighbors and, without correction, could lead to underestimation of density near the edges.Setting edge = TRUE ensures that edge correction is applied, which adjusts the density estimate near the borders to compensate for this bias.\nTo avoid negative intensity values, for kernel methods I will choose \"quartic\".\n\n\nPlotting our results\nSince we are analysing the same geographical area over a period of time, and we want to apply the same amount of smoothing, I am going to use the sigma value derived from the first quarter using bw.scott and apply it to all quarters.\n\nkde_sigma &lt;- bw.scott(conflictMYQ1_ppp.km)\nkde_conflictMYQ1.bw &lt;- density(conflictMYQ1_ppp.km, sigma=kde_sigma, edge=TRUE, kernel=\"quartic\")\nkde_conflictMYQ2.bw &lt;- density(conflictMYQ2_ppp.km, sigma=kde_sigma, edge=TRUE, kernel=\"quartic\")\nkde_conflictMYQ3.bw &lt;- density(conflictMYQ3_ppp.km, sigma=kde_sigma, edge=TRUE, kernel=\"quartic\")\nkde_conflictMYQ4.bw &lt;- density(conflictMYQ4_ppp.km, sigma=kde_sigma, edge=TRUE, kernel=\"quartic\")\n\nNext, I am going to convert this into a raster object to make it ggplot2 compatible, to make it easier to plot with:\n\nkde_conflictMYQ1_raster &lt;- raster(kde_conflictMYQ1.bw)\nkde_conflictMYQ2_raster &lt;- raster(kde_conflictMYQ2.bw)\nkde_conflictMYQ3_raster &lt;- raster(kde_conflictMYQ3.bw)\nkde_conflictMYQ4_raster &lt;- raster(kde_conflictMYQ4.bw)\n\nLet us take a look at the properties of the RasterLayers created.\n\nkde_conflictMYQ1_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 7.302001, 16.30032  (x, y)\nextent     : -210.0086, 724.6476, 1072.026, 3158.467  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -3.294221e-17, 0.04563376  (min, max)\n\n\nNotice that the crs property is NA. We need to set it to an appropriate value.\n\nprojection(kde_conflictMYQ1_raster) &lt;- CRS(\"+init=EPSG:32647\")\nprojection(kde_conflictMYQ2_raster) &lt;- CRS(\"+init=EPSG:32647\")\nprojection(kde_conflictMYQ3_raster) &lt;- CRS(\"+init=EPSG:32647\")\nprojection(kde_conflictMYQ4_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nNow, it’s finally time to plot the data.\n\n1st quarter\n\nraster_map &lt;- tm_shape(kde_conflictMYQ1_raster) + \n  tm_raster(\"layer\", palette = \"viridis\", title = \"Conflict intensity\") +\n  tm_layout(legend.position = c(\"left\", \"bottom\"), frame = FALSE)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the scale of the\nvisual variable `col` namely 'palette' (rename to 'values') to col.scale =\ntm_scale(&lt;HERE&gt;).\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the legend of the\nvisual variable `col` namely 'title' to 'col.legend = tm_legend(&lt;HERE&gt;)'\n\nboundary_map &lt;- tm_shape(boundaries) +\n  tm_borders() +\n  tm_text(\"ST\", size = 0.3, col = \"blue\")\ntmap_arrange(raster_map, boundary_map, ncol=2)\n\n\n\n\n\n\n\n\nThe map reveals that much of the conflict occurred in Sagaing and Magway, with localized fighting in Shan (South) and Kayah, and another significant hotspot in Yangon. This aligns with news reports indicating that during the first quarter of 2022, the Myanmar conflict was primarily concentrated in Rakhine, Chin, Sagaing, and Magway regions. Sagaing and Magway, in particular, saw numerous battles involving the People’s Defence Forces (PDF), while Chin State experienced substantial conflict due to its proximity to India and the presence of active ethnic insurgent groups. Meanwhile, Rakhine State remained a key battleground for clashes between the Arakan Army (AA) and the Tatmadaw.\nSagaing and Magway became strongholds for the PDF, local militias that formed in response to the military coup. These regions saw widespread opposition to military rule, with strong support for the armed struggle against the Tatmadaw. The terrain in Sagaing, in particular, provided resistance groups with strategic advantages for carrying out guerrilla-style attacks on military convoys and outposts.\nYangon, Myanmar’s largest city, also became a significant hotspot during this period. While most rural areas were engulfed in insurgency and military battles, urban resistance in Yangon consisted of sabotage operations, targeted assassinations, and bombings orchestrated by the PDF and other resistance groups. These attacks targeted military personnel, government officials, and infrastructure, making Yangon a focal point of urban conflict.\nIn Shan (South) and Kayah, localized conflicts arose due to territorial disputes and long-standing tensions. Both regions are home to multiple ethnic armed groups, and the fighting reflected ongoing struggles for control and autonomy in the area.\n\n\n2nd quarter\n\nraster_map &lt;- tm_shape(kde_conflictMYQ2_raster) + \n  tm_raster(\"layer\", palette = \"viridis\", title = \"Conflict intensity\") +\n  tm_layout(legend.position = c(\"left\", \"bottom\"), frame = FALSE)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the scale of the\nvisual variable `col` namely 'palette' (rename to 'values') to col.scale =\ntm_scale(&lt;HERE&gt;).\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the legend of the\nvisual variable `col` namely 'title' to 'col.legend = tm_legend(&lt;HERE&gt;)'\n\nboundary_map &lt;- tm_shape(boundaries) +\n  tm_borders() +\n  tm_text(\"ST\", size = 0.3, col = \"blue\")\ntmap_arrange(raster_map, boundary_map, ncol=2)\n\n\n\n\n\n\n\n\nIn the second quarter, fighting became more concentrated in Sagaing, Magway, and Chin State. In particular, the conflict in Chin State intensified as clashes escalated between the Tatmadaw and ethnic insurgent groups, including the Chin National Front (CNF) and local PDF forces. Chin State’s strategic location near the Indian border made it a key theater of conflict, prompting increased military offensives against insurgent strongholds. This led to more intense military operations and a rise in human rights abuses, such as arbitrary detentions and targeted attacks on civilians.\nMeanwhile, conflict in Shan (South)/Kayah and Yangon showed signs of abating. The Tatmadaw redirected its focus to the more intense fighting in Sagaing, Magway, and Chin, which had become central battlegrounds due to the growing strength of the PDF. This shift likely reduced military pressure in Shan (South) and Kayah, contributing to the decline in conflict there. Additionally, reports of temporary ceasefires or negotiation efforts between the Tatmadaw and some ethnic armed organizations (EAOs) may have contributed to the decrease in reported conflicts, although these ceasefires are often fragile.\nTanintharyi experienced a rise in reported conflicts during the second quarter. Previously, this southern Myanmar region had been relatively less impacted by the conflict, but by quarter 2, it saw increased activity due to escalating resistance from local People’s Defence Forces (PDF) and clashes with the military. The region’s strategic coastal position and its proximity to Thailand likely played a role in its growing importance in the conflict.\n\n\n3rd quarter\n\nraster_map &lt;- tm_shape(kde_conflictMYQ3_raster) + \n  tm_raster(\"layer\", palette = \"viridis\", title = \"Conflict intensity\") +\n  tm_layout(legend.position = c(\"left\", \"bottom\"), frame = FALSE)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the scale of the\nvisual variable `col` namely 'palette' (rename to 'values') to col.scale =\ntm_scale(&lt;HERE&gt;).\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the legend of the\nvisual variable `col` namely 'title' to 'col.legend = tm_legend(&lt;HERE&gt;)'\n\nboundary_map &lt;- tm_shape(boundaries) +\n  tm_borders() +\n  tm_text(\"ST\", size = 0.3, col = \"blue\")\ntmap_arrange(raster_map, boundary_map, ncol=2)\n\n\n\n\n\n\n\n\nBetween quarters 2 and 3, the conflict in Shan (South) and Kayah significantly decreased, while fighting in Yangon returned to the intensity seen in quarter 1. The People’s Defence Forces (PDF) and other resistance groups likely resumed urban operations, including sabotage, bombings, and targeted assassinations, directed at military personnel and government officials. This resurgence indicates a renewal of urban resistance despite heightened military crackdowns. Meanwhile, Rakhine State experienced a sharp rise in reported conflicts. The Arakan Army (AA) intensified its efforts against the Tatmadaw, seeking greater control over the region. The AA’s renewed activity led to more frequent clashes, with the fighting spreading to more densely populated areas, worsening the humanitarian crisis.\n\n\n4th quarter\n\nraster_map &lt;- tm_shape(kde_conflictMYQ4_raster) + \n  tm_raster(\"layer\", palette = \"viridis\", title = \"Conflict intensity\") +\n  tm_layout(legend.position = c(\"left\", \"bottom\"), frame = FALSE)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the scale of the\nvisual variable `col` namely 'palette' (rename to 'values') to col.scale =\ntm_scale(&lt;HERE&gt;).\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the legend of the\nvisual variable `col` namely 'title' to 'col.legend = tm_legend(&lt;HERE&gt;)'\n\nboundary_map &lt;- tm_shape(boundaries) +\n  tm_borders() +\n  tm_text(\"ST\", size = 0.3, col = \"blue\")\ntmap_arrange(raster_map, boundary_map, ncol=2)\n\n\n\n\n\n\n\n\nIn quarter 4, fighting became more localized in Sagaing, while conflict in Chin State subsided. However, hostilities persisted in Rakhine, Yangon, and Tanintharyi.\nIn Sagaing, the fighting intensified and became more concentrated, likely due to the Tatmadaw’s increased efforts to suppress resistance forces, particularly in rural areas where the People’s Defence Forces (PDF) operated. The region’s terrain, which is conducive to guerrilla tactics, allowed resistance groups to continue their operations, despite the fighting being confined to specific pockets. The Tatmadaw may have redirected more resources to Sagaing, leading to a reduction in larger-scale battles elsewhere.\nEarlier in the year, Chin State had experienced heavy fighting, but by quarter 4, both sides may have been experiencing resource exhaustion, resulting in a relative lull in conflict. The state’s terrain and its cross-border dynamics with India may have also contributed to the decrease in confrontations.\nRakhine State remained a key battleground, with ongoing clashes between the Arakan Army (AA) and the Tatmadaw. The AA’s growing strength and territorial ambitions fueled the conflict as they sought greater autonomy for the region. The Tatmadaw likely prioritized Rakhine due to its strategic importance along the Bay of Bengal.\nTanintharyi continued to witness fighting, largely due to its strategic location and the rising presence of resistance groups. Its proximity to the Thai border made the region a crucial area for supply routes and safe havens for resistance forces, resulting in sustained military clashes.\n\n\nSummary\n\nq1_graph &lt;- tm_shape(kde_conflictMYQ1_raster) + \n  tm_raster(\"layer\", palette = \"viridis\", title = \"Conflict intensity\") +\n  tm_layout(legend.position = c(\"left\", \"bottom\"), frame = FALSE, legend.title.size = 1)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the scale of the\nvisual variable `col` namely 'palette' (rename to 'values') to col.scale =\ntm_scale(&lt;HERE&gt;).\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the legend of the\nvisual variable `col` namely 'title' to 'col.legend = tm_legend(&lt;HERE&gt;)'\n\nq2_graph &lt;- tm_shape(kde_conflictMYQ2_raster) + \n  tm_raster(\"layer\", palette = \"viridis\", title = \"Conflict intensity\") +\n  tm_layout(legend.position = c(\"left\", \"bottom\"), frame = FALSE, legend.title.size = 1)\n\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the legend of the\nvisual variable `col` namely 'title' to 'col.legend = tm_legend(&lt;HERE&gt;)'\n\nq3_graph &lt;- tm_shape(kde_conflictMYQ3_raster) + \n  tm_raster(\"layer\", palette = \"viridis\", title = \"Conflict intensity\") +\n  tm_layout(legend.position = c(\"left\", \"bottom\"), frame = FALSE, legend.title.size = 1)\n\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the legend of the\nvisual variable `col` namely 'title' to 'col.legend = tm_legend(&lt;HERE&gt;)'\n\nq4_graph &lt;- tm_shape(kde_conflictMYQ4_raster) + \n  tm_raster(\"layer\", palette = \"viridis\", title = \"Conflict intensity\") +\n  tm_layout(legend.position = c(\"left\", \"bottom\"), frame = FALSE, legend.title.size = 1)\n\n[v3-&gt;v4] `tm_raster()`: migrate the argument(s) related to the legend of the\nvisual variable `col` namely 'title' to 'col.legend = tm_legend(&lt;HERE&gt;)'\n\ntmap_arrange(q1_graph, q2_graph, q3_graph, q4_graph, asp=2, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nIs the conflict clustered or dispersed?\nWe can use Clark-Evans test to test for whether the distribution of conflicts is clustered or dispersed across Myanmar. This can help us understand the underlying patterns and drivers of conflict. If the conflict events are clustered in specific areas, it suggests the presence of hotspots driven by factors such as ethnic tensions, military strategies, or geographical advantages.\nSince I am coming in with the notion that the distribution of conflicts are highly clustered. I am going to use a one-tailed Clark-Evans test. I am however not going to use edge correction for my test, as I personally feel that the study area is large enough that it is not sufficient to result in fewer neighbours along the boundaries. In fact, data so far has shown that that is in fact the opposite. Fighting seemed more intense in areas bordering India and Thailand.\nThe test hypotheses are:\nHo = The distribution of conflicts are randomly distributed (complete spatial randomness when R = 1).\nH1= The distribution of conflicts are not randomly distributed (the events are clustered and closer together than expected under random distribution when R &lt; 1).\nThe 95% confident interval will be used.\n\nconflictMY_ppp &lt;- superimpose(conflictMYQ1_ppp, conflictMYQ2_ppp, conflictMYQ3_ppp, conflictMYQ4_ppp)\n\n\nclarkevans.test(conflictMY_ppp,\n                correction=\"none\",\n                clipregion=\"national_boundaries_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  conflictMY_ppp\nR = 0.16171, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nSince our R-value is less than 1, it indicates clustering. In this case, R = 0.16171, which is significantly less than 1, indicating that the conflicts are clustered.\nThe p-value represents the probability of observing such a clustered pattern under the null hypothesis of randomness. A p-value less than the significance level (α = 0.05) allows us to reject the null hypothesis. In this case, the p-value is extremely small (essentially zero), far below the 0.05 threshold.\nSince R &lt; 1 and the p-value is extremely small, we reject the null hypothesis.\nThis means we have strong evidence to conclude that the distribution of conflicts is not randomly distributed. Instead, the distribution is clustered. Conflicts tend to be closer together than what would be expected under a random spatial distribution."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nd-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nd-order-spatial-point-patterns-analysis",
    "title": "Take Home Exercise 1",
    "section": "2nd-order Spatial Point Patterns Analysis",
    "text": "2nd-order Spatial Point Patterns Analysis\nTo do our 2nd order spatial point analysis, let’s focus on the Sagaing, the state where the conflicts was the most fiercest in 2022.\n\nconflict_data_2022_sagaing &lt;- conflict_data %&gt;% filter(admin1 == \"Sagaing\") %&gt;% filter(year == 2022)\nconflict_data_2022_sagaing_ppp &lt;- as.ppp(conflict_data_2022_sagaing)\n\nWarning in as.ppp.sf(conflict_data_2022_sagaing): only first attribute column\nis used for marks\n\n\n\nunitname(conflict_data_2022_sagaing_ppp)\n\nunit / units \n\n\nThe unit of the ppp function has not been set. Let’s set it to metres based on the CRS.\n\nunitname(conflict_data_2022_sagaing_ppp) &lt;- c(\"metre\", \"metres\")\n\n\nF-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape.\nThe F-function measures the cumulative distribution of distances from a random point in the study region to the nearest point in the point pattern. Essentially, it answers the question: “given a random location in the study area, what is the probability that the nearest point in the pattern is within a distance r”?\n\nx-axis (r): Represents the distance from a random point in the study area to the nearest point in the pattern.\ny-axis (F(r)): Represents the cumulative probability that the distance from a random location to the nearest point is less than or equal to r.\n\n\nF_Sagaing = Fest(conflict_data_2022_sagaing_ppp)\nplot(F_Sagaing)\n\n\n\n\n\n\n\n\n\nThe solid line represents the empirical F-function (F(r)), which shows the distribution of distances from random points in the study area to the nearest observed point.\nThe dashed line represents the theoretical F-function under complete spatial randomness (CSR). This line helps you compare the observed point pattern to a random point distribution.\n\nThe small gradient in the F-function at short distances suggests that many random locations in the study area have no nearby conflict events. This implies that conflict events are sparse or dispersed at smaller scales.\nAround the 2000-meter mark, the F-function shows a more linear increase, indicating that random locations start to have a consistent distance to the nearest conflict event. Beyond this point, events are regularly spaced, implying a more uniform distribution.\nThe initial slow rise suggests conflict events are far from random locations at small scales, while the linear rise beyond 2000 meters points to a consistent spacing pattern. This may reflect conflict clustering in specific areas, with gaps between them, and more predictable event proximity at larger distances.\nConflict events may be concentrated in specific areas like towns, military bases, or strategic locations, with gaps in between, resulting in regular spacing at a larger scale. At shorter distances, fewer events occur, indicating less frequent conflict, but beyond around 2000 meters, events become more consistently distributed.\n\nHypothesis testing\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of conflicts at Sagaing are randomly distributed.\nH1= The distribution of conflicts at Sagaing are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nF_Sagaing.csr &lt;- envelope(conflict_data_2022_sagaing_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_Sagaing.csr)\n\n\n\n\n\n\n\n\n\n\n\nL-Function\nThe K-function measures the number of events found up to a given distance of any particular event.\nIt answers the question: “how many additional points are found within a distance r from an average point, compared to what would be expected if the points were randomly distributed”?\nThe L-function is a transformation of the K-function designed to make it easier to interpret the results of spatial point pattern analysis. The L-function is often used because it linearizes the K-function under the assumption of complete spatial randomness (CSR), making deviations from randomness easier to detect.\nLinear Under CSR: Under complete spatial randomness (CSR), the L-function should be approximately equal to the distance r.\n\nClustering: If the observed is above the line, it indicates clustering at distance r. There are more points close to each other than expected under CSR.\nDispersion: If the observed is below the line, it indicates regularity or dispersion at distance r. The points are more evenly spaced than expected under CSR.\n\n\nL_ck = Lest(conflict_data_2022_sagaing_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", xlim=c(0,50000))\n\n\n\n\n\n\n\n\nThe decrease in the K-function up to 5000 meters suggests point dispersion at smaller distances. The sharp increase at 5000 meters indicates the start of clustering, with local clusters becoming more apparent. The gradual rise between 5000 and 25000 meters reflects increasing clustering across larger areas, possibly indicating regional-scale grouping of points, like towns or strategic locations. The second sharp increase at 25,000 meters suggests larger clusters or groups of clusters, indicating broader patterns in how the points are distributed. Beyond 25,000 meters, clustering continues across even larger distances, pointing to an overall structure where points are organized into regional clusters. Beyond 25000 meters, clustering continues across even larger distances, pointing to an overall structure where points are organized into regional clusters.\nThe regular spacing up to 5000 meters could be due to geographic barriers or strategic factors preventing clustering. The sharp increase at 5000 meters suggests localized clusters, possibly in towns or military zones, while the second increase at 25000 meters reflects a larger, regional-scale clustering. Beyond 25000 meters, the upward trend indicates that these clusters are part of a broader pattern, with conflict events in different regions still showing interdependence over larger distances.\n\nHypothesis testing\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of conflicts at Sagaing are randomly distributed.\nH1= The distribution of conflicts at Sagaing are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\n\nL_Sagaing.csr &lt;- envelope(conflict_data_2022_sagaing_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_Sagaing.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,50000))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, tmap)\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/In-class_Ex/In-class_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nSimple features are represented via “simple features geometry (SFG)”, and they and geospatial data can be represented with “simple features objects (SFO)” which represent a collection of SFG as a data-frame object. The non-spatial data (metadata) are stored in a separate column separate from the SFG column. The data type of that SFG column is known as “simple features collection (SFC)”.\nSFO is an object, you can get the class by passing in a variable to the class function.\nIn the environments tab, “obs” stands for observations which is basically the number of rows. “Variables” represent the number of columns.\nThe data types you will be working with for each column would be:\n\nint\nchr\n\nBasically a string.\n\nDate\nnum\n\nA superclass of int and double. R will automatically cast it to its child classes if needed, but this is basically a generic number class.\n\n\n\n\nmpsz2019 &lt;- st_read(dsn = \"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\") %&gt;% st_transform(crs = 3414)\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/In-class_Ex/In-class_Ex02/data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nIf you look at the KML version, you can see that it is less tidier than the Shapefile version.\n&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/…\nYou’ll have to manually parse and extract the data. Hence, the Shapefile version will be the one we are going to use.\n\ntm_shape(mpsz)+\n  tm_fill(\"REGION_N\", \n          style = \"quantile\",\n          palette = \"plasma\",\n          title = \"Subzones\") +\n  tm_layout(main.title = \"Planning subzones of Singapore (2014)\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\")\n\n\n\n\n\n\n\n\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/In-class_Ex/In-class_Ex02/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\npreschool3414 &lt;- st_transform(preschool, crs = 3414)\n\n\npopdata &lt;- st_read(\"data/aspatial/respopagesextod2023.csv\")\n\nReading layer `respopagesextod2023' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/In-class_Ex/In-class_Ex02/data/aspatial/respopagesextod2023.csv' \n  using driver `CSV'\n\n\nWarning: no simple feature geometries present: returning a data.frame or tbl_df\n\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "Spatial Point Pattern Analysis involves assessing the distribution of points on a surface to understand underlying patterns. In this context, the points of interest are the locations of childcare centers in Singapore. The analysis seeks to answer two key questions:\n\nAre the childcare centers in Singapore randomly distributed across the country?\n\nThis question examines whether the placement of childcare centers follows a random pattern or if there is some underlying structure influencing their distribution.\n\nIf the distribution is not random, where are the locations with a higher concentration of childcare centers?\n\nThis question aims to identify specific areas in Singapore that have a higher density of childcare centers, indicating potential clusters or hotspots.\n\n\nUsing functions from the spatstat package, the analysis will explore the spatial point processes governing the distribution of childcare centers, providing insights into the randomness or clustering of these facilities.\n\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex04/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex04/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex04/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nNow let’s check if the data imported has the correct projections:\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nNow, let’s assign the correct CRS to the following data:\n\nmpsz_sf &lt;- mpsz_sf %&gt;% st_set_crs(3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(mpsz_sf) +\n  tm_fill() + # draw polygons without borders\n  tm_borders() + # draw borders\n  tm_shape(childcare_sf) +\n  tm_dots() # draw points\n\n\n\n\n\n\n\n\nThe advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\nAlways remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nNow, we need to convert the generic sp objects into spatstat’s ppp object.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let’s plot childcare_ppp:\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nIn spatial point pattern analysis, the concept of duplicates or coincident points refers to multiple points that occupy the exact same location in space.\nMany statistical methods in spatial point pattern analysis are based on the assumption that the underlying point process is simple. A simple point process means that no two points in the process can occupy the exact same location (i.e., they cannot be coincident).\nIf points are coincident, this assumption is violated, and the statistical methods that rely on this assumption may produce invalid or misleading results.\nThus, let’s check if there are any duplicate points:\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nAs you can see, there doesn’t seem to be any duplicated data point.\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below:\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nTo view the locations of any duplicate point events, we will plot childcare data by using the code chunk below:\n\ncoincident_points &lt;- childcare_sf[duplicated(st_geometry(childcare_sf)), ]\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(coincident_points) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering. It is used to add a small amount of random noise to the coordinates of points in a spatial point pattern. This process, often referred to as “jittering,” helps to separate coincident points (points that have the exact same coordinates) by moving them slightly apart. This can be particularly useful in spatial analyses where coincident points might violate assumptions, such as the assumption that points are not exactly coincident.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nLet’s see if there are any duplicates now:\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nNow, we will convert these sf objects into owin objects that is required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\nNow why would you bother to split them up? To analyse spatial randomness it is essential to exclude regions like the airport where there are no childcare centres.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main=\"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, you will learn how to compute G-function estimation by using Gest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\nNote that it is typical for randomness to occur when the area of analysis is high. It is important to figure out that at what distance does clustering occur and at what distance randomness starts to appear again. This can be done using the L function. We can further modify the L function to make it from a diagonal to a straight line. We have lots of different functions, like G function (zonal - within a ring buffer, how many points are there, and slowly draw more and more bigger rings, so unlike K function it is not cumulative, there is no straight version of it) or K function (the L function is the same as the K function except a transformation is applied to the result to make the graph straight, making it easier to interpret). Each employ a different shape but they are all distance based. Some analyse distances zone by zone while some are cumulative.\nIt essentially answers the question: “given a point in the spatial pattern, what is the probability that the nearest neighboring point is within a certain distance r”?\n\nx-axis (r): This represents the distance (in the same units as your spatial data).\ny-axis (G(r)): This is the cumulative probability that the nearest neighbor distance is less than or equal to r.\n\n\n\nThe code chunk below is used to compute G-function using Gest() of spatat package for the Chua Chu Kang planning area.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\nIf the curve rises steeply at short distances, it indicates that most points have a nearby neighbor, suggesting a clustered pattern. If the curve rises more gradually, it indicates a more dispersed pattern where points are further apart on average. A linear increase in the G-function typically suggests a random or Poisson process, where points are randomly distributed. If you have plotted the theoretical G-function (usually a straight line), deviations from this line indicate either clustering (curve above the theoretical line) or regularity (curve below the theoretical line).\nThe correction = \"border\" parameter adjusts the G-function to account for edge effects, which occur because points near the boundary of the study region have fewer neighboring points within the study area.\nxlim=c(0,500) limits the distance axis to between 0 and 500 units. You would analyze the curve within this range to understand the distribution of nearest neighbor distances among your spatial points.\nNow for the Tampines planning area:\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nSince you are using more simulation iterations, the time taken to run the tests will be longer. Since this is essentially Monte Carlo simulation, to satisfy a 95% confidence interval, we need a minimum of 39 for convergence. 99, 199, 999 are common values. We need a greater amount to achieve a more stable result. Note that 99 means that you are running it 100 times.\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\nFor the Tampines planning area:\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)\n\n\n\n\n\n\n\n\nNote that it is typical for randomness to occur when the area of analysis is high. It is important to figure out that at what distance does clustering occur and at what distance randomness starts to appear again. This can be done using the L function. We can further modify the L function to make it from a diagonal to a straight line. We have lots of different functions, like G function (zonal - within a ring buffer, how many points are there, and slowly draw more and more bigger rings, so unlike K function it is not cumulative, there is no straight version of it) or K function (the L function is the same as the K function except a transformation is applied to the result to make the graph straight, making it easier to interpret). Each employ a different shape but they are all distance based. Some analyse distances zone by zone while some are cumulative.\nAlso, if you need a constant result, you have to set the seed. You only have to set the seed once at the top of the document for maximum reproducibility.\n\n\n\n\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, you will learn how to compute F-function estimation by using Fest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\nThe F-function measures the cumulative distribution of distances from a random point in the study region to the nearest point in the point pattern. Essentially, it answers the question: “given a random location in the study area, what is the probability that the nearest point in the pattern is within a distance r”?\n\nx-axis (r): Represents the distance from a random point in the study area to the nearest point in the pattern.\ny-axis (F(r)): Represents the cumulative probability that the distance from a random location to the nearest point is less than or equal to r.\n\nA steep rise in the F-function at short distances indicates that most random locations are close to points in the pattern, suggesting a clustered distribution. A more gradual increase suggests that random locations tend to be farther away from points, indicating a more dispersed or regular distribution. Like the G-function, the F-function can be compared against a theoretical model (e.g., a completely random pattern, or CSR). A higher-than-expected F-function indicates clustering, while a lower-than-expected F-function suggests regularity. The F-function focuses on distances from random points to the nearest point in the pattern, while the G-function focuses on distances between points within the pattern itself. The G-function tends to be more sensitive to clustering at short distances, while the F-function can provide complementary information, particularly about the spacing and distribution relative to the overall study area.\nNow for the Tampines planning area:\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\nFor the Tampines planning area:\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)\n\n\n\n\n\n\n\n\n\n\n\n\nK-function measures the number of events found up to a given distance of any particular event. In this section, you will learn how to compute K-function estimates by using Kest() of spatstat package. You will also learn how to perform Monte Carlo simulation test using envelope() of spatstat package.\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\nThe K-function answers the question: “how many additional points are found within a distance r from an average point, compared to what would be expected if the points were randomly distributed”?\nUnlike the G-function (which looks at nearest neighbor distances) or the F-function (which looks at distances from random points to the nearest pattern points), the K-function considers all pairs of points within the pattern. It helps assess clustering or dispersion over a range of distances.\nThe K-function compares the observed number of points within a certain distance r of each point in the pattern to what you would expect if the points were distributed according to a completely spatially random (CSR) process.\n\nx-axis (r): Represents the distance r from a typical point in the pattern.\ny-axis (K(r)): Represents the cumulative count of neighboring points within distance r, adjusted for the density of the points.\n\n\n\nCSR (Complete Spatial Randomness) Line: If the points are randomly distributed, the K-function typically follows a linear relationship with distance r.\nAbove the CSR Line (K(r) &gt; CSR): If the observed K-function curve is above the CSR line, it indicates clustering, meaning there are more points within distance r than expected under randomness.\nBelow the CSR Line (K(r) &lt; CSR): If the curve is below the CSR line, it suggests regularity or dispersion, meaning points are more spaced out than expected under randomness.\n\nWhen calculating the K-function, edge corrections are often applied to adjust for boundary effects, where points near the edges of the study area might have fewer neighbors simply because the area cuts off.\nImagine you’re analyzing the spatial distribution of trees in a forest. The K-function would help you understand whether trees tend to cluster together or are regularly spaced over different distances. If your K-function plot shows significant clustering at certain distances, you might infer that trees in this forest tend to grow in groups rather than being evenly spread out.\nNow for the Tampines planning area:\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\nThis limits the x-axis to a range from 0 to 1000 meters. This means the plot will only show the K-function values for distances up to 1000 meters.\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\nFor the Tampines planning area:\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to compute L-function estimation by using Lest() of spatstat package. You will also learn how to perform Monte Carlo simulation test using envelope() of spatstat package.\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\nThe L-function is a transformation of the K-function designed to make it easier to interpret the results of spatial point pattern analysis. The L-function is often used because it linearizes the K-function under the assumption of complete spatial randomness (CSR), making deviations from randomness easier to detect.\nLinear Under CSR: Under complete spatial randomness (CSR), the L-function should be approximately equal to the distance r.\n\nClustering: If the observed is above the line, it indicates clustering at distance r. There are more points close to each other than expected under CSR.\nDispersion: If the observed is below the line, it indicates regularity or dispersion at distance r. The points are more evenly spaced than expected under CSR.\n\nNow for the Tampines planning area:\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\nFor the Tampines planning area:\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "pacman::p_load(sf, raster, spatstat, tmap, tidyverse)\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex04/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex04/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex04/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nNow let’s check if the data imported has the correct projections:\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nNow, let’s assign the correct CRS to the following data:\n\nmpsz_sf &lt;- mpsz_sf %&gt;% st_set_crs(3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#mapping-the-geospatial-data-sets",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "tmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(mpsz_sf) +\n  tm_fill() + # draw polygons without borders\n  tm_borders() + # draw borders\n  tm_shape(childcare_sf) +\n  tm_dots() # draw points\n\n\n\n\n\n\n\n\nThe advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\nAlways remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nNow, we need to convert the generic sp objects into spatstat’s ppp object.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let’s plot childcare_ppp:\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nIn spatial point pattern analysis, the concept of duplicates or coincident points refers to multiple points that occupy the exact same location in space.\nMany statistical methods in spatial point pattern analysis are based on the assumption that the underlying point process is simple. A simple point process means that no two points in the process can occupy the exact same location (i.e., they cannot be coincident).\nIf points are coincident, this assumption is violated, and the statistical methods that rely on this assumption may produce invalid or misleading results.\nThus, let’s check if there are any duplicate points:\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nAs you can see, there doesn’t seem to be any duplicated data point.\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below:\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nTo view the locations of any duplicate point events, we will plot childcare data by using the code chunk below:\n\ncoincident_points &lt;- childcare_sf[duplicated(st_geometry(childcare_sf)), ]\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(coincident_points) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering. It is used to add a small amount of random noise to the coordinates of points in a spatial point pattern. This process, often referred to as “jittering,” helps to separate coincident points (points that have the exact same coordinates) by moving them slightly apart. This can be particularly useful in spatial analyses where coincident points might violate assumptions, such as the assumption that points are not exactly coincident.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nLet’s see if there are any duplicates now:\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nNow, we will convert these sf objects into owin objects that is required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\nNow why would you bother to split them up? To analyse spatial randomness it is essential to exclude regions like the airport where there are no childcare centres.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main=\"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#analysing-spatial-point-process-using-g-function",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "The G function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, you will learn how to compute G-function estimation by using Gest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\nNote that it is typical for randomness to occur when the area of analysis is high. It is important to figure out that at what distance does clustering occur and at what distance randomness starts to appear again. This can be done using the L function. We can further modify the L function to make it from a diagonal to a straight line. We have lots of different functions, like G function (zonal - within a ring buffer, how many points are there, and slowly draw more and more bigger rings, so unlike K function it is not cumulative, there is no straight version of it) or K function (the L function is the same as the K function except a transformation is applied to the result to make the graph straight, making it easier to interpret). Each employ a different shape but they are all distance based. Some analyse distances zone by zone while some are cumulative.\nIt essentially answers the question: “given a point in the spatial pattern, what is the probability that the nearest neighboring point is within a certain distance r”?\n\nx-axis (r): This represents the distance (in the same units as your spatial data).\ny-axis (G(r)): This is the cumulative probability that the nearest neighbor distance is less than or equal to r.\n\n\n\nThe code chunk below is used to compute G-function using Gest() of spatat package for the Chua Chu Kang planning area.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\nIf the curve rises steeply at short distances, it indicates that most points have a nearby neighbor, suggesting a clustered pattern. If the curve rises more gradually, it indicates a more dispersed pattern where points are further apart on average. A linear increase in the G-function typically suggests a random or Poisson process, where points are randomly distributed. If you have plotted the theoretical G-function (usually a straight line), deviations from this line indicate either clustering (curve above the theoretical line) or regularity (curve below the theoretical line).\nThe correction = \"border\" parameter adjusts the G-function to account for edge effects, which occur because points near the boundary of the study region have fewer neighboring points within the study area.\nxlim=c(0,500) limits the distance axis to between 0 and 500 units. You would analyze the curve within this range to understand the distribution of nearest neighbor distances among your spatial points.\nNow for the Tampines planning area:\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nSince you are using more simulation iterations, the time taken to run the tests will be longer. Since this is essentially Monte Carlo simulation, to satisfy a 95% confidence interval, we need a minimum of 39 for convergence. 99, 199, 999 are common values. We need a greater amount to achieve a more stable result. Note that 99 means that you are running it 100 times.\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\nFor the Tampines planning area:\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)\n\n\n\n\n\n\n\n\nNote that it is typical for randomness to occur when the area of analysis is high. It is important to figure out that at what distance does clustering occur and at what distance randomness starts to appear again. This can be done using the L function. We can further modify the L function to make it from a diagonal to a straight line. We have lots of different functions, like G function (zonal - within a ring buffer, how many points are there, and slowly draw more and more bigger rings, so unlike K function it is not cumulative, there is no straight version of it) or K function (the L function is the same as the K function except a transformation is applied to the result to make the graph straight, making it easier to interpret). Each employ a different shape but they are all distance based. Some analyse distances zone by zone while some are cumulative.\nAlso, if you need a constant result, you have to set the seed. You only have to set the seed once at the top of the document for maximum reproducibility.\n\n\n\n\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, you will learn how to compute F-function estimation by using Fest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\nThe F-function measures the cumulative distribution of distances from a random point in the study region to the nearest point in the point pattern. Essentially, it answers the question: “given a random location in the study area, what is the probability that the nearest point in the pattern is within a distance r”?\n\nx-axis (r): Represents the distance from a random point in the study area to the nearest point in the pattern.\ny-axis (F(r)): Represents the cumulative probability that the distance from a random location to the nearest point is less than or equal to r.\n\nA steep rise in the F-function at short distances indicates that most random locations are close to points in the pattern, suggesting a clustered distribution. A more gradual increase suggests that random locations tend to be farther away from points, indicating a more dispersed or regular distribution. Like the G-function, the F-function can be compared against a theoretical model (e.g., a completely random pattern, or CSR). A higher-than-expected F-function indicates clustering, while a lower-than-expected F-function suggests regularity. The F-function focuses on distances from random points to the nearest point in the pattern, while the G-function focuses on distances between points within the pattern itself. The G-function tends to be more sensitive to clustering at short distances, while the F-function can provide complementary information, particularly about the spacing and distribution relative to the overall study area.\nNow for the Tampines planning area:\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\nFor the Tampines planning area:\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)\n\n\n\n\n\n\n\n\n\n\n\n\nK-function measures the number of events found up to a given distance of any particular event. In this section, you will learn how to compute K-function estimates by using Kest() of spatstat package. You will also learn how to perform Monte Carlo simulation test using envelope() of spatstat package.\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\nThe K-function answers the question: “how many additional points are found within a distance r from an average point, compared to what would be expected if the points were randomly distributed”?\nUnlike the G-function (which looks at nearest neighbor distances) or the F-function (which looks at distances from random points to the nearest pattern points), the K-function considers all pairs of points within the pattern. It helps assess clustering or dispersion over a range of distances.\nThe K-function compares the observed number of points within a certain distance r of each point in the pattern to what you would expect if the points were distributed according to a completely spatially random (CSR) process.\n\nx-axis (r): Represents the distance r from a typical point in the pattern.\ny-axis (K(r)): Represents the cumulative count of neighboring points within distance r, adjusted for the density of the points.\n\n\n\nCSR (Complete Spatial Randomness) Line: If the points are randomly distributed, the K-function typically follows a linear relationship with distance r.\nAbove the CSR Line (K(r) &gt; CSR): If the observed K-function curve is above the CSR line, it indicates clustering, meaning there are more points within distance r than expected under randomness.\nBelow the CSR Line (K(r) &lt; CSR): If the curve is below the CSR line, it suggests regularity or dispersion, meaning points are more spaced out than expected under randomness.\n\nWhen calculating the K-function, edge corrections are often applied to adjust for boundary effects, where points near the edges of the study area might have fewer neighbors simply because the area cuts off.\nImagine you’re analyzing the spatial distribution of trees in a forest. The K-function would help you understand whether trees tend to cluster together or are regularly spaced over different distances. If your K-function plot shows significant clustering at certain distances, you might infer that trees in this forest tend to grow in groups rather than being evenly spread out.\nNow for the Tampines planning area:\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\nThis limits the x-axis to a range from 0 to 1000 meters. This means the plot will only show the K-function values for distances up to 1000 meters.\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\nFor the Tampines planning area:\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to compute L-function estimation by using Lest() of spatstat package. You will also learn how to perform Monte Carlo simulation test using envelope() of spatstat package.\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\nThe L-function is a transformation of the K-function designed to make it easier to interpret the results of spatial point pattern analysis. The L-function is often used because it linearizes the K-function under the assumption of complete spatial randomness (CSR), making deviations from randomness easier to detect.\nLinear Under CSR: Under complete spatial randomness (CSR), the L-function should be approximately equal to the distance r.\n\nClustering: If the observed is above the line, it indicates clustering at distance r. There are more points close to each other than expected under CSR.\nDispersion: If the observed is below the line, it indicates regularity or dispersion at distance r. The points are more evenly spaced than expected under CSR.\n\nNow for the Tampines planning area:\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\nFor the Tampines planning area:\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Spatial Point Pattern Analysis (SPPA) is a method used to evaluate the pattern or distribution of a set of points on a surface. To begin with, we need to gather data on the locations of these childcare centres and their corresponding coordinates. We can use geographic information systems (GIS) software to do this. Once we have this data, we can then analyze it using SPPA. The first step is to identify the spatial point processes that exist within a given area.\nAfter identifying these patterns, we can determine whether there are any locations with higher concentrations of childcare centres. This information can be used to gain insights into possible trends or patterns in the distribution of these centres, and help policy makers make informed decisions about where new centres should be located.\n\n\nIn this hands-on exercise, five R packages will be used, they are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex03/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nIn this case, CostalOutline is the name of the Shapefile.\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nIt seems like the projected CRS are all in order (SVY21).\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(mpsz_sf) +\n  tm_fill() + # draw polygons without borders\n  tm_borders() + # draw borders\n  tm_shape(childcare_sf) +\n  tm_dots() # draw points\n\n\n\n\n\n\n\n\nYou can also create a pin map using the Leaflet API:\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\nThe advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\nAlways remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nWhile simple features is popular, many geospatial packages still require sp’s Spatial class. Here is how we convert them back to Spatial:\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\nsummary(childcare)\n\nObject of class SpatialPointsDataFrame\nCoordinates:\n               min      max\ncoords.x1 11203.01 45404.24\ncoords.x2 25667.60 49300.88\ncoords.x3     0.00     0.00\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nNumber of points: 1545\nData attributes:\n     Name           Description       \n Length:1545        Length:1545       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\n\n\nsummary(mpsz)\n\nObject of class SpatialPolygonsDataFrame\nCoordinates:\n        min      max\nx  2667.538 56396.44\ny 15748.721 50256.33\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs]\nData attributes:\n    OBJECTID       SUBZONE_NO      SUBZONE_N          SUBZONE_C        \n Min.   :  1.0   Min.   : 1.000   Length:323         Length:323        \n 1st Qu.: 81.5   1st Qu.: 2.000   Class :character   Class :character  \n Median :162.0   Median : 4.000   Mode  :character   Mode  :character  \n Mean   :162.0   Mean   : 4.625                                        \n 3rd Qu.:242.5   3rd Qu.: 6.500                                        \n Max.   :323.0   Max.   :17.000                                        \n    CA_IND           PLN_AREA_N         PLN_AREA_C          REGION_N        \n Length:323         Length:323         Length:323         Length:323        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   REGION_C           INC_CRC            FMEL_UPD_D             X_ADDR     \n Length:323         Length:323         Min.   :2014-12-05   Min.   : 5093  \n Class :character   Class :character   1st Qu.:2014-12-05   1st Qu.:21864  \n Mode  :character   Mode  :character   Median :2014-12-05   Median :28465  \n                                       Mean   :2014-12-05   Mean   :27257  \n                                       3rd Qu.:2014-12-05   3rd Qu.:31674  \n                                       Max.   :2014-12-05   Max.   :50425  \n     Y_ADDR        SHAPE_Leng        SHAPE_Area      \n Min.   :19579   Min.   :  871.5   Min.   :   39438  \n 1st Qu.:31776   1st Qu.: 3709.6   1st Qu.:  628261  \n Median :35113   Median : 5211.9   Median : 1229894  \n Mean   :36106   Mean   : 6524.4   Mean   : 2420882  \n 3rd Qu.:39869   3rd Qu.: 6942.6   3rd Qu.: 2106483  \n Max.   :49553   Max.   :68083.9   Max.   :69748299  \n\n\n\nsummary(sg)\n\nObject of class SpatialPolygonsDataFrame\nCoordinates:\n        min      max\nx  2663.926 56047.79\ny 16357.981 50244.03\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs]\nData attributes:\n    GDO_GID          MSLINK          MAPID    COSTAL_NAM       \n Min.   : 1.00   Min.   : 1.00   Min.   :0   Length:60         \n 1st Qu.:15.75   1st Qu.:17.75   1st Qu.:0   Class :character  \n Median :30.50   Median :33.50   Median :0   Mode  :character  \n Mean   :30.50   Mean   :33.77   Mean   :0                     \n 3rd Qu.:45.25   3rd Qu.:49.25   3rd Qu.:0                     \n Max.   :60.00   Max.   :67.00   Max.   :0                     \n\n\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\n\n\nA ppp object is a type of data structure used in the spatstat package in R for handling spatial point pattern data. The ppp stands for “planar point pattern,” and it represents a collection of points that are typically used in the analysis of spatial point processes.\n\n\nThe ppp object contains the coordinates of the points in the point pattern. These are stored as two numeric vectors, x and y, which represent the Cartesian coordinates of the points.\n\n\n\nThis component defines the observation window, i.e., the area in which the points are observed. The window can be a simple rectangle or a more complex polygonal region. The window is typically an object of class owin, which specifies the boundaries within which the points are contained.\n\n\n\nThe ppp object can include additional data associated with each point, known as “marks.” Marks can be any type of data, such as categorical labels, numerical values, or even more complex data structures. Marks add a second level of information to the point pattern, allowing for marked point process analysis.\n\n\n\n\nFirst, we have to convert the sf Spatial classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\nsummary(childcare_sp)\n\nObject of class SpatialPoints\nCoordinates:\n               min      max\ncoords.x1 11203.01 45404.24\ncoords.x2 25667.60 49300.88\ncoords.x3     0.00     0.00\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nNumber of points: 1545\n\n\n\nsummary(sg_sp)\n\nObject of class SpatialPolygons\nCoordinates:\n        min      max\nx  2663.926 56047.79\ny 16357.981 50244.03\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs]\n\n\nNext, we need to convert the generic sp objects into spatstat’s ppp object.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let’s plot childcare_ppp:\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nIn spatial point pattern analysis, the concept of duplicates or coincident points refers to multiple points that occupy the exact same location in space.\nMany statistical methods in spatial point pattern analysis are based on the assumption that the underlying point process is simple. A simple point process means that no two points in the process can occupy the exact same location (i.e., they cannot be coincident).\nIf points are coincident, this assumption is violated, and the statistical methods that rely on this assumption may produce invalid or misleading results.\nThus, let’s check if there are any duplicate points:\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nAs you can see, there doesn’t seem to be any duplicated data point.\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below:\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nTo view the locations of any duplicate point events, we will plot childcare data by using the code chunk below:\n\ncoincident_points &lt;- childcare_sf[duplicated(st_geometry(childcare_sf)), ]\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(coincident_points) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering. It is used to add a small amount of random noise to the coordinates of points in a spatial point pattern. This process, often referred to as “jittering,” helps to separate coincident points (points that have the exact same coordinates) by moving them slightly apart. This can be particularly useful in spatial analyses where coincident points might violate assumptions, such as the assumption that points are not exactly coincident.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nLet’s see if there are any duplicates now:\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to perform first-order SPPA by using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n\nKernel Density Estimation (KDE) is a non-parametric method (does not assume any specific underlying distribution for the data) used to estimate the probability density function (PDF) of a random variable based on a finite sample of data points. In spatial analysis, KDE is often used to estimate the intensity or density of events (such as crime incidents, animal sightings, or disease cases) across a geographical area.\n\nClustered (groups of POI close together)\nRandom (spread out but with irregular spacing)\nUniform (spread out but have regular spacing)\n\nMapping stuff out is exploratory. To quantify it we can employ hypothesis testing.\nWe essentially count the number of points of interest in a particular area (which we can specify) and calculate the density (or intensity).\nIn this section, you will learn how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n\nNote: Even though it is called “automatic bandwidth”, they are considered fixed bandwidth methods (you calculate density with the same area throughout). Use adaptive bandwidth instead if you have highly skewed data. Use fixed bandwidth if you are comparing KDE between regions.\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe edge parameter controls whether edge correction should be applied. Edge correction accounts for the fact that points near the boundaries of the observation window have fewer neighbors and, without correction, could lead to underestimation of density near the edges.\nSetting edge = TRUE ensures that edge correction is applied, which adjusts the density estimate near the borders to compensate for this bias.\n\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\nThe bandwidth in the context of Kernel Density Estimation (KDE) is a critical parameter that determines the level of smoothing applied to the data when estimating the density. It controls how much each data point influences the estimate of the density around it.\nTo convert the unit of measurement from meter to kilometer:\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output KDE map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\n\n\n\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in their experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk below will be used to compare the output of using bw.diggle and bw.ppl methods:\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Discs.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\nThese are interpolations to deal with areas that has less data.\nIf you use Gaussian, you sometimes get negative intensity values, so try to avoid it. Try quartic instead.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\n\n\n\n\n\n\n\n\n\n\n\nSince the unit of measurement has changed to kilometres, the sigma value used is 0.6 instead of 600 metres.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\nThis approach is appropriate in several situations, particularly when the underlying data is relatively uniform in its distribution (extremely unlikely unless the area of analysis is small) and when the focus is on identifying broad trends or when the study area does not exhibit significant variations in density.\n\n\n\nYou can either visually inspect the plot, or use summary statistics.\n\nquadrat.test(childcareSG_ppp)\n\nWarning: Some expected counts are small; chi^2 approximation may be inaccurate\n\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  childcareSG_ppp\nX2 = 676.18, df = 20, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nQuadrats: 21 tiles (irregular windows)\n\n\nA significant result (low p-value) indicates that the points are not uniformly distributed and may be highly skewed, with clustering in certain areas.\n\n\n\n\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\nUnlike fixed bandwidth, we adjust the area according to the density of points.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\nThe result is the same, we just convert it so that it is suitable for mapping purposes.\n\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nNext, we will convert the gridded kernel density objects into RasterLayer object by using raster() of raster package.\nA raster is a type of data structure commonly used in Geographic Information Systems (GIS) to represent spatial data. It is a grid-based format that divides a geographic area into a matrix of cells or pixels, where each cell contains a value representing information such as elevation, temperature, land cover, or any other spatial attribute.\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -7.794268e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is NA.\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster RasterLayer.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -7.794268e-15, 28.51831  (min, max)\n\n\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n\n\nIn this section, you will learn how to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nNow, we will convert these sf objects into owin objects that is required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\nNow why would you bother to split them up? To analyse spatial randomness it is essential to exclude regions like the airport where there are no childcare centres.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main=\"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n\n\nFor comparison purposes, we will use 250m as the bandwidth.\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nR = 0.55631:\n\nThe R value is the Clark-Evans ratio, which compares the observed average nearest neighbor distance to the expected nearest neighbor distance for a random distribution.\nR = 1 indicates a random distribution.\nR &lt; 1 indicates clustering (i.e., the points are closer to each other than expected under randomness).\nR &gt; 1 indicates dispersion (i.e., the points are more evenly spread out than expected under randomness).\n\nIn this case, R = 0.55631, which is significantly less than 1, indicating that the childcare services are clustered.\np-value &lt; 2.2e-16:\n\nThe p-value represents the probability of observing such a clustered pattern under the null hypothesis of randomness.\nA p-value less than the significance level (α = 0.05) allows us to reject the null hypothesis. In this case, the p-value is extremely small (essentially zero), far below the 0.05 threshold.\n\nConclusion:\n\nSince R &lt; 1 and the p-value is extremely small, we reject the null hypothesis.\nThis means we have strong evidence to conclude that the distribution of childcare services in Singapore is not randomly distributed. Instead, the distribution is clustered—that is, the childcare services tend to be closer together than what would be expected under a random spatial distribution.\n\n\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nNull Hypothesis (Ho): The distribution of childcare services is randomly distributed (CSR, Complete Spatial Randomness).\nAlternative Hypothesis (H1): The distribution of childcare services is not randomly distributed. This includes both possibilities: the points may be either clustered (R &lt; 1) or regularly spaced (R &gt; 1). If the index is close or equal to 1, the patterns exhibit randomness.\n\nRegularity (also known as dispersion) in the context of spatial point patterns refers to a distribution where points are more evenly spaced than would be expected under complete spatial randomness (CSR). Essentially, regularity or dispersion implies that points are systematically spread out, avoiding clustering, and often maintaining a more uniform distance from each other.\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.8943, p-value = 0.1143\nalternative hypothesis: two-sided\n\n\n\nSince the p-value is large (0.4801), you fail to reject the null hypothesis (Ho). This means that the observed pattern of childcare services in childcare_ck_ppp is not significantly different from random.\nConclusion: The distribution of childcare services is consistent with complete spatial randomness (CSR). There is no statistically significant evidence to suggest that the points are either clustered or regularly spaced.\n\nNote: Since you are using more simulation iterations, the time taken to run the tests will be longer. Since this is essentially Monte Carlo simulation, to satisfy a 95% confidence interval, we need a minimum of 39 for convergence. 99, 199, 999 are common values. We need a greater amount to achieve a more stable result. Note that 99 means that you are running it 100 times.\nNote that it is typical for randomness to occur when the area of analysis is high. It is important to figure out that at what distance does clustering occur and at what distance randomness starts to appear again. This can be done using the L function. We can further modify the L function to make it from a diagonal to a straight line. We have lots of different functions, like G function (zonal - within a ring buffer, how many points are there, and slowly draw more and more bigger rings, so unlike K function it is not cumulative, there is no straight version of it) or K function (the L function is the same as the K function except a transformation is applied to the result to make the graph straight, making it easier to interpret). Each employ a different shape but they are all distance based. Some analyse distances zone by zone while some are cumulative.\nAlso, if you need a constant result, you have to set the seed. You only have to set the seed once at the top of the document for maximum reproducibility.\n\n\n\n\n\n\nWhen to Use:\n\nUse the one-sided test with the alternative = \"clustered\" option when you have a prior expectation or hypothesis that the points are more likely to be clustered rather than dispersed.\nExample: If you are studying the distribution of businesses that tend to cluster in urban centers, you might hypothesize that these businesses are more likely to be clustered due to factors like proximity to customers or each other.\n\nInterpretation:\n\nR &lt; 1: Supports the hypothesis that the points are clustered.\nR &gt; 1: Would indicate regular spacing, but this result would be unexpected and not directly tested in this scenario.\n\n\n\n\n\n\nWhen to Use:\n\nUse the one-sided test with alternative = \"regular\" (or sometimes alternative = \"dispersed\") when you suspect that points are more regularly spaced, perhaps due to competition, territoriality, or other factors that push points apart.\nExample: In ecology, if you are studying tree locations in a forest where trees are expected to be evenly spaced due to competition for resources, you might test for regular spacing.\n\nInterpretation:\n\nR &gt; 1: Supports the hypothesis that the points are regularly spaced.\nR &lt; 1: Would indicate clustering, but this result would be unexpected and not directly tested in this scenario.\n\n\n\n\n\n\n\nWhen to Use:\n\nUse the two-sided test with alternative = \"two.sided\" when you do not have a specific expectation about whether the points are clustered or dispersed, and you want to test for any significant deviation from complete spatial randomness (CSR).\nThis is appropriate when you are exploring the data without a strong prior hypothesis about the nature of the spatial distribution.\nExample: If you are conducting an exploratory analysis of a new dataset and are unsure whether the points might be clustered or dispersed, the two-sided test is appropriate.\n\nInterpretation:\n\nR &lt; 1 with a significant p-value: Indicates clustering.\nR &gt; 1 with a significant p-value: Indicates regular spacing.\nR ≈ 1 with a non-significant p-value: Indicates a random distribution.\n\n\n\n\n\n\nEdge Correction (correction parameter):\n\nUse edge correction if your study area is bounded (e.g., a city boundary, nature reserve) and the points near the boundary might have fewer neighbors simply due to being near the edge. This correction helps adjust for this bias.\nIf your study area is very large or if edge effects are not a concern, you might choose correction = \"none\", as in your examples.\n\n\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.79294, p-value = 0.0001862\nalternative hypothesis: two-sided\n\n\n\nSince the p-value is small (0.0004794), you reject the null hypothesis (Ho). This means that the observed pattern of childcare services in childcare_tm_ppp is significantly different from random.\nConclusion: The distribution of childcare services is consistent with complete spatial randomness (CSR). There is statistically significant evidence to suggest that the points are either clustered or regularly spaced."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this hands-on exercise, five R packages will be used, they are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex03/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nIn this case, CostalOutline is the name of the Shapefile.\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nIt seems like the projected CRS are all in order (SVY21)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#mapping-the-geospatial-data-sets",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "tmap_mode('plot')\n\ntmap mode set to plotting\n\ntm_shape(mpsz_sf) +\n  tm_fill() + # draw polygons without borders\n  tm_borders() + # draw borders\n  tm_shape(childcare_sf) +\n  tm_dots() # draw points\n\n\n\n\n\n\n\n\nYou can also create a pin map using the Leaflet API:\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\nThe advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\nAlways remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nWhile simple features is popular, many geospatial packages still require sp’s Spatial class. Here is how we convert them back to Spatial:\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\nsummary(childcare)\n\nObject of class SpatialPointsDataFrame\nCoordinates:\n               min      max\ncoords.x1 11203.01 45404.24\ncoords.x2 25667.60 49300.88\ncoords.x3     0.00     0.00\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nNumber of points: 1545\nData attributes:\n     Name           Description       \n Length:1545        Length:1545       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\n\n\nsummary(mpsz)\n\nObject of class SpatialPolygonsDataFrame\nCoordinates:\n        min      max\nx  2667.538 56396.44\ny 15748.721 50256.33\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs]\nData attributes:\n    OBJECTID       SUBZONE_NO      SUBZONE_N          SUBZONE_C        \n Min.   :  1.0   Min.   : 1.000   Length:323         Length:323        \n 1st Qu.: 81.5   1st Qu.: 2.000   Class :character   Class :character  \n Median :162.0   Median : 4.000   Mode  :character   Mode  :character  \n Mean   :162.0   Mean   : 4.625                                        \n 3rd Qu.:242.5   3rd Qu.: 6.500                                        \n Max.   :323.0   Max.   :17.000                                        \n    CA_IND           PLN_AREA_N         PLN_AREA_C          REGION_N        \n Length:323         Length:323         Length:323         Length:323        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   REGION_C           INC_CRC            FMEL_UPD_D             X_ADDR     \n Length:323         Length:323         Min.   :2014-12-05   Min.   : 5093  \n Class :character   Class :character   1st Qu.:2014-12-05   1st Qu.:21864  \n Mode  :character   Mode  :character   Median :2014-12-05   Median :28465  \n                                       Mean   :2014-12-05   Mean   :27257  \n                                       3rd Qu.:2014-12-05   3rd Qu.:31674  \n                                       Max.   :2014-12-05   Max.   :50425  \n     Y_ADDR        SHAPE_Leng        SHAPE_Area      \n Min.   :19579   Min.   :  871.5   Min.   :   39438  \n 1st Qu.:31776   1st Qu.: 3709.6   1st Qu.:  628261  \n Median :35113   Median : 5211.9   Median : 1229894  \n Mean   :36106   Mean   : 6524.4   Mean   : 2420882  \n 3rd Qu.:39869   3rd Qu.: 6942.6   3rd Qu.: 2106483  \n Max.   :49553   Max.   :68083.9   Max.   :69748299  \n\n\n\nsummary(sg)\n\nObject of class SpatialPolygonsDataFrame\nCoordinates:\n        min      max\nx  2663.926 56047.79\ny 16357.981 50244.03\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs]\nData attributes:\n    GDO_GID          MSLINK          MAPID    COSTAL_NAM       \n Min.   : 1.00   Min.   : 1.00   Min.   :0   Length:60         \n 1st Qu.:15.75   1st Qu.:17.75   1st Qu.:0   Class :character  \n Median :30.50   Median :33.50   Median :0   Mode  :character  \n Mean   :30.50   Mean   :33.77   Mean   :0                     \n 3rd Qu.:45.25   3rd Qu.:49.25   3rd Qu.:0                     \n Max.   :60.00   Max.   :67.00   Max.   :0                     \n\n\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\n\n\nA ppp object is a type of data structure used in the spatstat package in R for handling spatial point pattern data. The ppp stands for “planar point pattern,” and it represents a collection of points that are typically used in the analysis of spatial point processes.\n\n\nThe ppp object contains the coordinates of the points in the point pattern. These are stored as two numeric vectors, x and y, which represent the Cartesian coordinates of the points.\n\n\n\nThis component defines the observation window, i.e., the area in which the points are observed. The window can be a simple rectangle or a more complex polygonal region. The window is typically an object of class owin, which specifies the boundaries within which the points are contained.\n\n\n\nThe ppp object can include additional data associated with each point, known as “marks.” Marks can be any type of data, such as categorical labels, numerical values, or even more complex data structures. Marks add a second level of information to the point pattern, allowing for marked point process analysis.\n\n\n\n\nFirst, we have to convert the sf Spatial classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\nsummary(childcare_sp)\n\nObject of class SpatialPoints\nCoordinates:\n               min      max\ncoords.x1 11203.01 45404.24\ncoords.x2 25667.60 49300.88\ncoords.x3     0.00     0.00\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nNumber of points: 1545\n\n\n\nsummary(sg_sp)\n\nObject of class SpatialPolygons\nCoordinates:\n        min      max\nx  2663.926 56047.79\ny 16357.981 50244.03\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs]\n\n\nNext, we need to convert the generic sp objects into spatstat’s ppp object.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let’s plot childcare_ppp:\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nIn spatial point pattern analysis, the concept of duplicates or coincident points refers to multiple points that occupy the exact same location in space.\nMany statistical methods in spatial point pattern analysis are based on the assumption that the underlying point process is simple. A simple point process means that no two points in the process can occupy the exact same location (i.e., they cannot be coincident).\nIf points are coincident, this assumption is violated, and the statistical methods that rely on this assumption may produce invalid or misleading results.\nThus, let’s check if there are any duplicate points:\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nAs you can see, there doesn’t seem to be any duplicated data point.\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below:\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nTo view the locations of any duplicate point events, we will plot childcare data by using the code chunk below:\n\ncoincident_points &lt;- childcare_sf[duplicated(st_geometry(childcare_sf)), ]\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(coincident_points) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering. It is used to add a small amount of random noise to the coordinates of points in a spatial point pattern. This process, often referred to as “jittering,” helps to separate coincident points (points that have the exact same coordinates) by moving them slightly apart. This can be particularly useful in spatial analyses where coincident points might violate assumptions, such as the assumption that points are not exactly coincident.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nLet’s see if there are any duplicates now:\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nplot(childcareSG_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this section, you will learn how to perform first-order SPPA by using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n\nKernel Density Estimation (KDE) is a non-parametric method (does not assume any specific underlying distribution for the data) used to estimate the probability density function (PDF) of a random variable based on a finite sample of data points. In spatial analysis, KDE is often used to estimate the intensity or density of events (such as crime incidents, animal sightings, or disease cases) across a geographical area.\n\nClustered (groups of POI close together)\nRandom (spread out but with irregular spacing)\nUniform (spread out but have regular spacing)\n\nMapping stuff out is exploratory. To quantify it we can employ hypothesis testing.\nWe essentially count the number of points of interest in a particular area (which we can specify) and calculate the density (or intensity).\nIn this section, you will learn how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n\nNote: Even though it is called “automatic bandwidth”, they are considered fixed bandwidth methods (you calculate density with the same area throughout). Use adaptive bandwidth instead if you have highly skewed data. Use fixed bandwidth if you are comparing KDE between regions.\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe edge parameter controls whether edge correction should be applied. Edge correction accounts for the fact that points near the boundaries of the observation window have fewer neighbors and, without correction, could lead to underestimation of density near the edges.\nSetting edge = TRUE ensures that edge correction is applied, which adjusts the density estimate near the borders to compensate for this bias.\n\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\nThe bandwidth in the context of Kernel Density Estimation (KDE) is a critical parameter that determines the level of smoothing applied to the data when estimating the density. It controls how much each data point influences the estimate of the density around it.\nTo convert the unit of measurement from meter to kilometer:\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output KDE map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\n\n\n\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in their experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk below will be used to compare the output of using bw.diggle and bw.ppl methods:\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Discs.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\nThese are interpolations to deal with areas that has less data.\nIf you use Gaussian, you sometimes get negative intensity values, so try to avoid it. Try quartic instead.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\n\n\n\n\n\n\n\n\n\n\n\nSince the unit of measurement has changed to kilometres, the sigma value used is 0.6 instead of 600 metres.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\nThis approach is appropriate in several situations, particularly when the underlying data is relatively uniform in its distribution (extremely unlikely unless the area of analysis is small) and when the focus is on identifying broad trends or when the study area does not exhibit significant variations in density.\n\n\n\nYou can either visually inspect the plot, or use summary statistics.\n\nquadrat.test(childcareSG_ppp)\n\nWarning: Some expected counts are small; chi^2 approximation may be inaccurate\n\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  childcareSG_ppp\nX2 = 676.18, df = 20, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nQuadrats: 21 tiles (irregular windows)\n\n\nA significant result (low p-value) indicates that the points are not uniformly distributed and may be highly skewed, with clustering in certain areas.\n\n\n\n\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\nUnlike fixed bandwidth, we adjust the area according to the density of points.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\nThe result is the same, we just convert it so that it is suitable for mapping purposes.\n\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nNext, we will convert the gridded kernel density objects into RasterLayer object by using raster() of raster package.\nA raster is a type of data structure commonly used in Geographic Information Systems (GIS) to represent spatial data. It is a grid-based format that divides a geographic area into a matrix of cells or pixels, where each cell contains a value representing information such as elevation, temperature, land cover, or any other spatial attribute.\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -7.794268e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is NA.\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster RasterLayer.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -7.794268e-15, 28.51831  (min, max)\n\n\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n\n\nIn this section, you will learn how to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nNow, we will convert these sf objects into owin objects that is required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\nNow why would you bother to split them up? To analyse spatial randomness it is essential to exclude regions like the airport where there are no childcare centres.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main=\"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n\n\nFor comparison purposes, we will use 250m as the bandwidth.\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nR = 0.55631:\n\nThe R value is the Clark-Evans ratio, which compares the observed average nearest neighbor distance to the expected nearest neighbor distance for a random distribution.\nR = 1 indicates a random distribution.\nR &lt; 1 indicates clustering (i.e., the points are closer to each other than expected under randomness).\nR &gt; 1 indicates dispersion (i.e., the points are more evenly spread out than expected under randomness).\n\nIn this case, R = 0.55631, which is significantly less than 1, indicating that the childcare services are clustered.\np-value &lt; 2.2e-16:\n\nThe p-value represents the probability of observing such a clustered pattern under the null hypothesis of randomness.\nA p-value less than the significance level (α = 0.05) allows us to reject the null hypothesis. In this case, the p-value is extremely small (essentially zero), far below the 0.05 threshold.\n\nConclusion:\n\nSince R &lt; 1 and the p-value is extremely small, we reject the null hypothesis.\nThis means we have strong evidence to conclude that the distribution of childcare services in Singapore is not randomly distributed. Instead, the distribution is clustered—that is, the childcare services tend to be closer together than what would be expected under a random spatial distribution.\n\n\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nNull Hypothesis (Ho): The distribution of childcare services is randomly distributed (CSR, Complete Spatial Randomness).\nAlternative Hypothesis (H1): The distribution of childcare services is not randomly distributed. This includes both possibilities: the points may be either clustered (R &lt; 1) or regularly spaced (R &gt; 1). If the index is close or equal to 1, the patterns exhibit randomness.\n\nRegularity (also known as dispersion) in the context of spatial point patterns refers to a distribution where points are more evenly spaced than would be expected under complete spatial randomness (CSR). Essentially, regularity or dispersion implies that points are systematically spread out, avoiding clustering, and often maintaining a more uniform distance from each other.\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.8943, p-value = 0.1143\nalternative hypothesis: two-sided\n\n\n\nSince the p-value is large (0.4801), you fail to reject the null hypothesis (Ho). This means that the observed pattern of childcare services in childcare_ck_ppp is not significantly different from random.\nConclusion: The distribution of childcare services is consistent with complete spatial randomness (CSR). There is no statistically significant evidence to suggest that the points are either clustered or regularly spaced.\n\nNote: Since you are using more simulation iterations, the time taken to run the tests will be longer. Since this is essentially Monte Carlo simulation, to satisfy a 95% confidence interval, we need a minimum of 39 for convergence. 99, 199, 999 are common values. We need a greater amount to achieve a more stable result. Note that 99 means that you are running it 100 times.\nNote that it is typical for randomness to occur when the area of analysis is high. It is important to figure out that at what distance does clustering occur and at what distance randomness starts to appear again. This can be done using the L function. We can further modify the L function to make it from a diagonal to a straight line. We have lots of different functions, like G function (zonal - within a ring buffer, how many points are there, and slowly draw more and more bigger rings, so unlike K function it is not cumulative, there is no straight version of it) or K function (the L function is the same as the K function except a transformation is applied to the result to make the graph straight, making it easier to interpret). Each employ a different shape but they are all distance based. Some analyse distances zone by zone while some are cumulative.\nAlso, if you need a constant result, you have to set the seed. You only have to set the seed once at the top of the document for maximum reproducibility.\n\n\n\n\n\n\nWhen to Use:\n\nUse the one-sided test with the alternative = \"clustered\" option when you have a prior expectation or hypothesis that the points are more likely to be clustered rather than dispersed.\nExample: If you are studying the distribution of businesses that tend to cluster in urban centers, you might hypothesize that these businesses are more likely to be clustered due to factors like proximity to customers or each other.\n\nInterpretation:\n\nR &lt; 1: Supports the hypothesis that the points are clustered.\nR &gt; 1: Would indicate regular spacing, but this result would be unexpected and not directly tested in this scenario.\n\n\n\n\n\n\nWhen to Use:\n\nUse the one-sided test with alternative = \"regular\" (or sometimes alternative = \"dispersed\") when you suspect that points are more regularly spaced, perhaps due to competition, territoriality, or other factors that push points apart.\nExample: In ecology, if you are studying tree locations in a forest where trees are expected to be evenly spaced due to competition for resources, you might test for regular spacing.\n\nInterpretation:\n\nR &gt; 1: Supports the hypothesis that the points are regularly spaced.\nR &lt; 1: Would indicate clustering, but this result would be unexpected and not directly tested in this scenario.\n\n\n\n\n\n\n\nWhen to Use:\n\nUse the two-sided test with alternative = \"two.sided\" when you do not have a specific expectation about whether the points are clustered or dispersed, and you want to test for any significant deviation from complete spatial randomness (CSR).\nThis is appropriate when you are exploring the data without a strong prior hypothesis about the nature of the spatial distribution.\nExample: If you are conducting an exploratory analysis of a new dataset and are unsure whether the points might be clustered or dispersed, the two-sided test is appropriate.\n\nInterpretation:\n\nR &lt; 1 with a significant p-value: Indicates clustering.\nR &gt; 1 with a significant p-value: Indicates regular spacing.\nR ≈ 1 with a non-significant p-value: Indicates a random distribution.\n\n\n\n\n\n\nEdge Correction (correction parameter):\n\nUse edge correction if your study area is bounded (e.g., a city boundary, nature reserve) and the points near the boundary might have fewer neighbors simply due to being near the edge. This correction helps adjust for this bias.\nIf your study area is very large or if edge effects are not a concern, you might choose correction = \"none\", as in your examples.\n\n\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.79294, p-value = 0.0001862\nalternative hypothesis: two-sided\n\n\n\nSince the p-value is small (0.0004794), you reject the null hypothesis (Ho). This means that the observed pattern of childcare services in childcare_tm_ppp is significantly different from random.\nConclusion: The distribution of childcare services is consistent with complete spatial randomness (CSR). There is statistically significant evidence to suggest that the points are either clustered or regularly spaced."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "Welcome to the IS415 Geospatial Analytics and Applications home page. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome! I’m Eugene Toh, an undergraduate student at Singapore Management University. I created this course website to document my learning journey in IS415: Geospatial Analytics and Applications, taught by Professor Kam Tin Seong. Join me as I explore the realms of big data, geospatial analysis, and urban planning."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman to check if tidyverse and sf are installed in the computer. If they are, they will be loaded by R.\n\npacman::p_load(sf, tidyverse)\n\n\n\n\n\n\n\nmpsz = st_read(dsn = \"data/geospatial/Master_Plan_2014_Subzone\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex01/data/geospatial/Master_Plan_2014_Subzone' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\ncyclingpath = st_read(\"data/geospatial/Cycling_Path_2014\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex01/data/geospatial/Cycling_Path_2014' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\n\npreschool = st_read(\"data/geospatial/PreSchool_Location/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex01/data/geospatial/PreSchool_Location/PreSchoolsLocation.kml' \n  using driver `LIBKML'\nSimple feature collection with 2290 features and 16 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman to check if tidyverse and sf are installed in the computer. If they are, they will be loaded by R.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "mpsz = st_read(dsn = \"data/geospatial/Master_Plan_2014_Subzone\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex01/data/geospatial/Master_Plan_2014_Subzone' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\ncyclingpath = st_read(\"data/geospatial/Cycling_Path_2014\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex01/data/geospatial/Cycling_Path_2014' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\n\npreschool = st_read(\"data/geospatial/PreSchool_Location/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex01/data/geospatial/PreSchool_Location/PreSchoolsLocation.kml' \n  using driver `LIBKML'\nSimple feature collection with 2290 features and 16 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adjusting-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adjusting-the-data",
    "title": "Hands-on Exercise 1",
    "section": "Adjusting the data",
    "text": "Adjusting the data\n\nAdjusting the EPSG code\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nTransforming the coordinate system\n\npreschool3414 &lt;- st_transform(preschool, crs = 3414)\n\n\nst_crs(preschool3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-data",
    "title": "Hands-on Exercise 1",
    "section": "Plotting the data",
    "text": "Plotting the data\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nPlotting a single attribute\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-aspatial-data",
    "title": "Hands-on Exercise 1",
    "section": "Working with Aspatial data",
    "text": "Working with Aspatial data\nAspatial data is data that is not geospatial in nature but contains fields that capture the x- and y-coordinates of the data points.\n\nImporting the data\n\nlistings &lt;- read_csv(\"data/aspatial/SG_Airbnb_Listing_Data/listings.csv\")\n\nRows: 3540 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (38): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nReading the data\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2024-06-29   city … B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.02e13 2024-06-29   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2024-06-29   city … 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2024-06-29   city … 15 m… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Book… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2024-06-29   city … 5 mi… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2024-06-29   city … Comf… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2024-06-29   city … Rela… **IMPORTAN…\n10 344803 https://www.airbnb.co…   2.02e13 2024-06-29   city … Budg… Direct bus…\n# … with 3,530 more rows, and 68 more variables: neighborhood_overview &lt;chr&gt;,\n#   picture_url &lt;chr&gt;, host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;,\n#   host_since &lt;date&gt;, host_location &lt;chr&gt;, host_about &lt;chr&gt;,\n#   host_response_time &lt;chr&gt;, host_response_rate &lt;chr&gt;,\n#   host_acceptance_rate &lt;chr&gt;, host_is_superhost &lt;lgl&gt;,\n#   host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;, host_neighbourhood &lt;chr&gt;,\n#   host_listings_count &lt;dbl&gt;, host_total_listings_count &lt;dbl&gt;, …\n\n\n\nExtracting the coordinates of each listing from the csv file and converting it into a data frame\n\nlistings_sf &lt;- st_as_sf(listings, coords = c(\"longitude\", \"latitude\"), crs=4326) %&gt;% st_transform(crs=3414)\n\nNote that %&gt;% is the pipe operator in R. EPSG: 4326 is wgs84 and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. Refer to the EPSG website for details.\n\n\n\nListing each row of the csv file\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.024063e+13, 2.024063e+1…\n$ last_scraped                                 &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"city …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1 …\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"99%…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ host_total_listings_count                    &lt;dbl&gt; 11, 11, 11, 73, 73, 11, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; NA, 0.5, 0.5, 2.0, 2.5, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, 1, 1, 1, 1, 3, 2, 1, 1…\n$ beds                                         &lt;dbl&gt; NA, 1, 2, 1, 1, NA, 1, 1,…\n$ amenities                                    &lt;chr&gt; \"[\\\"Free parking on premi…\n$ price                                        &lt;chr&gt; NA, \"$80.00\", \"$80.00\", \"…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 30, 30, 28, 0, 29, 30…\n$ availability_60                              &lt;dbl&gt; 59, 53, 60, 58, 0, 58, 60…\n$ availability_90                              &lt;dbl&gt; 89, 83, 90, 62, 0, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 3…\n$ calendar_last_scraped                        &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 6, 49…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Hands-on Exercise 1",
    "section": "Buffering",
    "text": "Buffering\nGetting the total area of land required for widening the existing cycling path by 5 metres:\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, dist=5, nQuadSegs=30)\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1",
    "section": "Point-in-polygon count",
    "text": "Point-in-polygon count\nGetting the number of pre-schools in each planning sub-zone. st_intersects merge both the sub-zone and the pre-school data, while lengths does the counting.\n\nmpsz3414$`PreSch Count` &lt;- lengths(st_intersects(mpsz3414, preschool3414))\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\nglimpse(mpsz3414)\n\nRows: 323\nColumns: 17\n$ OBJECTID       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ SUBZONE_NO     &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2,…\n$ SUBZONE_N      &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON…\n$ SUBZONE_C      &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ…\n$ CA_IND         &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", …\n$ PLN_AREA_N     &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MER…\n$ PLN_AREA_C     &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"…\n$ REGION_N       &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"…\n$ REGION_C       &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"…\n$ INC_CRC        &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0…\n$ FMEL_UPD_D     &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-1…\n$ X_ADDR         &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358…\n$ Y_ADDR         &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991…\n$ SHAPE_Leng     &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.…\n$ SHAPE_Area     &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44,…\n$ geometry       &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYG…\n$ `PreSch Count` &lt;int&gt; 0, 6, 0, 5, 3, 13, 5, 1, 11, 1, 4, 2, 0, 1, 6, 0, 0, 0,…\n\n\nGetting the districts with the most number of pre-schools.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nCalculate the density of pre-schools of each district.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;% st_area()\nmpsz3414 &lt;- mpsz3414 %&gt;% mutate(`PreSch Density` = `PreSch Count` / Area * 1000000)\nglimpse(mpsz3414)\n\nRows: 323\nColumns: 19\n$ OBJECTID         &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…\n$ SUBZONE_NO       &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, …\n$ SUBZONE_N        &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERS…\n$ SUBZONE_C        &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BM…\n$ CA_IND           &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\"…\n$ PLN_AREA_N       &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT M…\n$ PLN_AREA_C       &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\",…\n$ REGION_N         &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\",…\n$ REGION_C         &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC          &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13…\n$ FMEL_UPD_D       &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014…\n$ X_ADDR           &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 253…\n$ Y_ADDR           &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 299…\n$ SHAPE_Leng       &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 442…\n$ SHAPE_Area       &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.4…\n$ geometry         &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOL…\n$ `PreSch Count`   &lt;int&gt; 0, 6, 0, 5, 3, 13, 5, 1, 11, 1, 4, 2, 0, 1, 6, 0, 0, …\n$ Area             [m^2] 1630379.27 [m^2], 559816.25 [m^2], 160807.50 [m^2], 5…\n$ `PreSch Density` [1/m^2] 0.0000000 [1/m^2], 10.7178026 [1/m^2], 0.0000000 [1…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Note: Lessons learned from hands-on exercises are documented in the notes tab.\nThematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices. Geovisualisation, on the other hand, works by providing graphical ideation to render a place, a phenomenon or a process visible.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nWe also need to convert the values in PA and SZ fields to uppercase, as the casing for both of these fields are inconsistent, so we need to normalise it. Moreover, both SUBZONE_N and PLN_AREA_N needs to be uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. We are going to use choropleth maps to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\",\n    fill.palette =\"plasma\")\n\n\n\n\n\n\n\n\nTo create a higher quality cartographic choropleth map that includes more accurate and informative information:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"plasma\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nTo draw the basic simple features:\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\nDrawing using the target variable “dependency”:\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThis is essentially the same thing as:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"plasma\",\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"plasma\",\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nAs you can see, equal data classification is not particularly suited for heavily skewed data.\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"plasma\",\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"plasma\",\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nAs you can see, the values are z-values.\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"plasma\",\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"plasma\",\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\n\n\nIt is always a good practice to get some descriptive statistics on the variable before setting the break points.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nTo invert the colours, you can do this:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nUsing ncols in tm_fill is one way to help you achieve this effect.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\nAnother way is by using tm_facets.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\nMultiple small choropleth maps can also be created by creating multiple stand-alone maps with tmap_arrange.\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nYou can also use a selection function to choose which spatial objects to include in your choropleth map.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "mpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/home/tropicbliss/Documents/GitHub/quarto-project/Hands-on_Ex/Hands-on_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-wrangling",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Before a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nWe also need to convert the values in PA and SZ fields to uppercase, as the casing for both of these fields are inconsistent, so we need to normalise it. Moreover, both SUBZONE_N and PLN_AREA_N needs to be uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#cloropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#cloropleth-mapping",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. We are going to use choropleth maps to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\",\n    fill.palette =\"plasma\")\n\n\n\n\n\n\n\n\nTo create a higher quality cartographic choropleth map that includes more accurate and informative information:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"plasma\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nTo draw the basic simple features:\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\nDrawing using the target variable “dependency”:\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThis is essentially the same thing as:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"plasma\",\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"plasma\",\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nAs you can see, equal data classification is not particularly suited for heavily skewed data.\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"plasma\",\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"plasma\",\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nAs you can see, the values are z-values.\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"plasma\",\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"plasma\",\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\n\n\nIt is always a good practice to get some descriptive statistics on the variable before setting the break points.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nTo invert the colours, you can do this:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nUsing ncols in tm_fill is one way to help you achieve this effect.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\nAnother way is by using tm_facets.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\nMultiple small choropleth maps can also be created by creating multiple stand-alone maps with tmap_arrange.\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nYou can also use a selection function to choose which spatial objects to include in your choropleth map.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "install.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\nsg_sf &lt;- mpsz_sf %&gt;% st_union()\nThe analog of ppp and owin in sf. The as.* methods are used for conversion which can convert from data-frames which is essentially how SFOs are represented.\nThe reason why as.SpatialGridDataFrame.im does not work is because maptools is not installed.\n\npacman::p_load(dplyr, sf, tidyverse, tmap)\nacled_sf &lt;- read_csv(\"data/ACLED_Myanmar.csv\") %&gt;% st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;% st_transform(crs = 32647) %&gt;% mutate(event_date = dmy(event_date))\n\nRows: 55574 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): event_id_cnty, event_date, disorder_type, event_type, sub_event_ty...\ndbl (11): year, time_precision, inter1, inter2, interaction, iso, latitude, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ntmap_mode(\"view\")\nacled_sf %&gt;% filter(year == 2023 | event_type == \"Political violence\") %&gt;% tm_shape() + tm_dots()\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1: Geospatial Data Science",
    "section": "",
    "text": "pacman::p_load(\"sf\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(sf, raster, spatstat, sparr, tmap, tidyverse)\n\n\ngeography &lt;- st_read(\"data/rawdata\") %&gt;% st_union() %&gt;% st_zm(drop = TRUE, what = \"ZM\") %&gt;% st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `/home/tropicbliss/GitHub/quarto-project/In-class_Ex/In-class_Ex04/data/rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nst_as_s2(): dropping Z and/or M coordinate\n\n\nPolygon Z: polygons with height data, you need to remove it.\nConverting it into owin:\n\nkbb_owin &lt;- as.owin(geography)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\nChecking whether it is really an owin:\n\nclass(kbb_owin)\n\n[1] \"owin\"\n\n\n\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\") %&gt;% st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;% st_transform(crs = 32748) # do not switch order of latlong\n\nRows: 741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): satellite, instrument, daynight\ndbl  (11): latitude, longitude, brightness, scan, track, acq_time, confidenc...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNow, you want separate fields for day, month, and year for easier data filtering. The DayOfYear field takes the number of days in a year into account.\n\nfire_sf &lt;- fire_sf %&gt;% mutate(DayOfYear = yday(acq_date)) %&gt;%\n  mutate(Month_num = month(acq_date)) %&gt;%\n  mutate(Month_fac = month(acq_date, label = TRUE, abbr = FALSE))\n\n\ntm_shape(geography) +\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nUse tm_symbols or tm_markers if you have a custom point logo.\nPolygon &gt; line &gt; point.\nA facet is a set of maps.\n\ntm_shape(geography) +\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots(size = 0.1) +\n  tm_facets(by = \"Month_fac\", free.coords = FALSE, drop.units = TRUE)\n\n\n\n\n\n\n\n\nfree.coords make sure that each map has the same map extent.\nExtracting by month:\n\nfire_month &lt;- fire_sf %&gt;% select(Month_num)\n\nCreating ppp (to use spatstat):\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\n\nsummary(fire_month_ppp)\n\nMarked planar point pattern:  741 points\nAverage intensity 2.49258e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n                    (174200 x 170600 units)\nWindow area = 29728200000 square units\n\n\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\nSpatio-temporal KDE:\n\nst_kde &lt;- spattemp.density(fire_month_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\nMost of the fires started from July onwards:\n\ntims &lt;- c(7, 8, 9, 10, 11, 12)\npar(mfcol=c(2, 3))\nfor (i in tims) {\n  plot(st_kde, i, override.par=FALSE, fix.range=TRUE, main = paste(\"KDE at month\", i))\n}\n\n\n\n\n\n\n\n\nInstead of using month, you can use day which can make the value of lambda more meaningful."
  },
  {
    "objectID": "Notes/notes.html",
    "href": "Notes/notes.html",
    "title": "Notes",
    "section": "",
    "text": "GIS is a software tool to analyse and visualise geographical information, it’s not a discipline.\nGeospatial analysis turns data into information that we can make decisions on.\nGeospatial data is data stored in a special database that can be thought of as a simplified model of the real world.\nWhat is a data-frame?\n\nA data structure organised as a table where data is organised in rows and columns. Each column typically stores data of a single data type. You can think of it as a spreadsheet or a database table. It can be manipulated via operations like filtering or grouping data.\n\nTypes of geospatial data\n\nVector\n\nStores data that are discrete in nature (you can count the total number of data that is representable)\nThe SVG of geospatial data\nData primitives (simple features)\n\nPoints\n\nCoordinate\nExamples\n\nLandmarks\n\n\nPolyline (line + polygon)\n\nSeries of coordinates known as vertices (though like other data types they might also contain additional metadata such as road names)\nExamples\n\nRoads\n\n\nPolygon\n\nConsists of three or more line segments, and the starting and end coordinates must be the same, but how they are stored is almost the same as how vertices are stored in a polyline.\nBuildings\n\n\n\nRaster (simple features)\n\nStores data that are continuous in nature (data that does not have a clear cut off point)\nThe JPEG of geospatial data\nElevation\nThe area of interest is divided into cells (which are essentially pixels on the screen). A grid typically only stores a single attribute of the area of interest, and each grid is responsible for a certain real world area size (such as 10x10 metres). The data stored in each grid is fixed. For instance, a grid can store a single 32 bit floating point value.\n\n\nCoordinate system\n\nCoordinates stored in different coordinate systems will have wildly different values relative to each other.\nTypes\n\nGeographical coordinate systems\n\nUses a three dimensional system to encode data\n\nLatitude\n\nVertical line\n0 degrees at the equator, +90 degrees in the north pole and -90 degrees in the south pole\n\nLongitude\n\nHorizontal line\n\n0 degrees at Greenwich\n\n0 to +180 degrees (east)\n0 to -180 degrees (west)\n\n\n\nDatum\n\nDefines the shape and the size of the earth as the equator or Greenwich while being used as a reference for the coordinate system does not define how much it varies as you stray further away from it.\nExamples\n\nWGS84\n\nDefines the earth as an ellipsoid\n\n\n\n\nNot suitable for distance measurement as it takes the curvature of the earth into account which makes it more challenging to calculate. A single degree of difference can lead to different distances depending on the coordinates of the start and end points.\n\nProjected coordinate system\n\nExamples\n\nSVY21 (Singapore) (EPSG code: 3414)\n\nProvides consistent area measurements.\nImportant to convert from GCS to PCS before conducting analysis.\nLarge countries might use multiple PCS.\nEach country or state might have their own PCS to minimise distortions from projecting a spherical surface into a plane, to create an accurate representation of an area.\nMake sure to convert to this form before doing any analysis.\n\n\n\nSimple features\n\nThere are about 17 of them, 3 of them having been mentioned above.\nMost software typically only use a subset of them.\nTypes\n\nPoint\n\nPoint(30, 10)\n\nMulti point\n\nMultiPoint([Point(10, 40), Point(40, 30), Point(20, 20), Point(30, 10)])\n\nLine string\n\nLineString([Point(30, 10), Point(10, 30), Point(40, 40)])\n\nPolygon\n\nPolygon([Point(30, 10), Point(40, 40), Point(20, 40), Point(10, 20), Point(30, 10)])\nPolygon([[Point(35, 10), Point(45, 45), Point(15, 40), Point(10, 20), Point(35, 10)], [Point(20, 30), Point(35, 35), Point(30, 20), Point(20, 30)]])\n\nMultiX\n\n“Multi” versions of the above primitives but have them be elements of an array.\n\n\nTo work with simple features, you can use the sf package from R which is part of the tidyverse collection.\nSimple features are represented via “simple features geometry (SFG)”, and they and geospatial data can be represented with “simple features objects (SFO)” which represent a collection of SFG as a data-frame object. The non-spatial data (metadata) are stored in a separate column separate from the SFG column. The data type of that SFG column is known as “simple features collection (SFC)”.\n\nsf functions\n\nsf also provides functions that help you in doing data manipulation and analysis of spatial data.\nst_read: import a file or database into a SFO (more flexible but slower)\n\nread_sf: import a file or database into a SFO (less flexible but more optimised)\nShapefiles can contain many layers, such as elevation that shows different data on the same geography. Each layer can have multiple attributes.\nSupported file formats\n\nShapefile\n\nA misnomer as it is basically a collection of files (hence a single shp file is not enough). File extensions include: dbf, prj, shp, xml, and shx.\ndsn stands for destination.\nsf_mpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE\")\nst_write(st_poly, \"data/my_poly.shp\")\n\nMapInfo TAB\nKML (Google)\nsf_preschool = st_read(\"data/geospatial/pre-schools-location-kml.kml\")\nYou need to provide the file extension if it is not a Shapefile.\nGML\nGeoJSON (popular in web)\nTopoJSON (popular in web)\n\n\nst_write: export a file from a SFO to a file or database\n\nwrite_sf: export a file from a SFO to a file or database (less flexible but more optimised)\n\nst_as_sf: convert existing data structures into a SFO\nst_as_text: convert a SFO into “well-known text” (WKT) (it is the to_string() of SFO and represents the SFO data structure in a textual format)\nst_as_binary: converts a SFO into a binary format\nst_transform: Convert a SFO into another SFO with a different coordinate reference system via an EPSG code. For example, it can convert GCS data to PCS.\n\nA coordinate reference system is a system that specifies the datum (among other attributes) of the coordinate system. It can be represented as a numerical code known as the EPSG code.\n\nst_intersects: whether two geometries touch or overlap each other\n\nNote that many sf functions may sound similar to each other but perform totally different tasks. For instance, st_intersects checks whether each geometry in each SFO intersects with each other while st_intersection will create new geometry that shows the areas of intersection.\nMany other functions in this category work the same way, and they all typically return a sparse list.\nSparse lists\n\nA sparse list is a way of efficiently representing the relationship of a geometry in one set with respect to another geometry in another set without using a full matrix.\nUsing st_intersects:\n# Example sparse list\nresult &lt;- list(\n  c(2, 3),\n  integer(0),\n  c(1, 4)\n)\n\nresult[[1]] (First Geometry in A):\n\nThe first element c(2, 3) means that the first geometry in A intersects with the 2nd and 3rd geometries in B.\n\nresult[[2]] (Second Geometry in A):\n\nThe second element integer(0) (an empty integer vector) means that the second geometry in A does not intersect with any geometry in B.\n\nresult[[3]] (Third Geometry in A):\n\nThe third element c(1, 4) means that the third geometry in A intersects with the 1st and 4th geometries in B.\n\nNote that sparse lists do not include symmetric pairs, e.g., (2, 4 and (4, 2) are repeated.\n\n\n\nFunctions that return a logical matrix indicating whether each geometry pair meets the logical operation\n\nst_disjoint: equivalent to performing a NOT boolean operation on the result of st_intersects\nst_touches: touch\nst_crosses: cross\nst_within: within\nst_contains: overlap\nst_overlaps: overlaps\nst_covers: cover\nst_covered_by: covered by\nst_equals: equals\nst_equals_exact: equals, with some fuzz\n\nReturns a sparse (default) or dense logical matrix.\n\n\nGeometry generating logical operators:\n\nst_union: union of several geometries\nst_intersection: intersection of pairs of geometries\nst_difference: difference between pairs of geometries\n\nIf st_difference(A, B), take A and subtract any areas of overlap by B.\n\nst_sym_difference: symmetric difference (XOR)\n\nEquivalent to st_union(st_difference(A, B), st_difference(B, A)).\n\n\nOther miscellaneous functions:\n\nst_area calculates the area of the geometries of the SFO given to it as a parameter and outputs a data-frame column.\n\nFor example, to calculate the area of each geometry, you can do:\nsfo$Area &lt;- sfo %&gt;% st_area()\n\nsum is an aggregation function that takes in a data-frame column and returns a number.\n\nHigher level operations\n\naggregate\nsummarise\nst_interpolate_aw: area-weighted interpolation of attributes from one set of geometries to another\n\nArea-weighted interpolation is a spatial analysis technique used to estimate or transfer values from one set of spatial units (e.g., polygons) to another set of spatial units that may overlap or have different boundaries. For instance, you might have census tracts for population and want to map out the population of each district. The census tract does not match the district. Hence, you will want to use this function to transfer population data over.\nYou need to specify the source and target geometries, each of which are SFOs, but the target geometry does not need to have any attributes. You also need to specify whether the interpolation is done extensively or intensively.\nIn extensive interpolation, you need to sum the contributions from each source polygon based on the proportion of its area that overlaps with the target polygon. For example, if you have a source polygon with a population of 1000 people and it overlaps by 50% with a target polygon, the area-weighted interpolation would allocate 500 people to the target polygon.\nIntensive attributes are those that are independent of the size or extent of the spatial unit they are associated with. These attributes describe a characteristic that does not change when you change the size of the area. An example of an intensive attribute is population density. For example, if one source polygon has a population density of 200 people per square kilometer and overlaps by 50% with a target polygon, and another source polygon has a density of 100 people per square kilometer and overlaps by 50%, the resulting population density in the target polygon would be the weighted average of these densities.\n\nst_join: performs spatial joins between two SFOs\n\nA spatial join merges attributes from one SFO to another.\nThe output SFO will retain the geometries of the first input SFO.\nThink of the second input SFO as an overlay for the first SFO.\n\n\n\nIllustration of st_join\n\n\nObserve that st_join does not do any interpolation or any mathematical operations. It also does not include any points in b. Any repeating data from the merge is included in the final output as an additional row.\n\npacman::p_load(sf)\na = st_sf(a = 1:3,\n geom = st_sfc(st_point(c(1,1)), st_point(c(2,2)), st_point(c(3,3))))\nb = st_sf(a = 11:15,\n geom = st_sfc(st_point(c(10,10)), st_point(c(2,2)), st_point(c(2,2)), st_point(c(3,3)), st_point(c(12,12))))\nst_join(a, b)\n\nSimple feature collection with 4 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 1 ymin: 1 xmax: 3 ymax: 3\nCRS:           NA\n    a.x a.y        geom\n1     1  NA POINT (1 1)\n2     2  12 POINT (2 2)\n2.1   2  13 POINT (2 2)\n3     3  14 POINT (3 3)\n\n\n\n\nManipulating geometries (spatial data wrangling) (generates new data out of existing data) (the output SFC does not contain any input data)\n\nst_line_merge: merges lines\nst_segmentize: adds points to straight lines\nst_voronoi: creates voronoi tesselation\nst_centroid: gives centroid of geometry\n\nOutputs a SFC containing points corresponding to the centre of each geometry.\n\nst_convex_hull: creates convex hull of set of points\nst_triangulate: triangulates sets of points (not constrained)\nst_polygonize: creates polygon from lines that form a closed ring\nst_simplify: simplifies lines by removing vertices\nst_split: split a polygon given line boundary\nst_buffer: compute a buffer around this geometry/each geometry\n\nTakes an SFO as input.\nCreates a region that expands outwards from each geometry by a given distance, creating a buffer zone.\nFor points, it creates a circular buffer. For lines, it creates a buffer along the entire length of the line, creating a polygon that surrounds the line. For polygons, it expands the polygon by a given distance, keeping it’s shape, resulting in a scaled up version of the original polygon.\nReturns a SFC containing only the buffer.\nUses the unit of measurement specified by the PCS, e.g., SVY21 (Singapore) uses metres as the unit of measurement.\nnQuadSegs determine the smoothness of the circular arcs that make up the buffer. The more the number of quad segments the smoother the curve. It’s typically sufficient to leave this as the default.\n\nst_make_valid: tries to make an invalid geometry valid (requires lwgeom)\nst_boundary: returns the boundary of a geometry\n\nConvenience functions\n\nst_zm: sets or removes z and/or m geometry\nst_coordinates: retrieves coordinates in a matrix or data frame\nst_geometry: sets, or retrieves SFC from an SFO\n\nReturns the SFC.\n\nst_is: checks whether a geometry is of a particular type\n\n\nOther functions\n\nglimpse: part of the dplyr package\n\nUsed to analyse any R object, but especially useful for tidyverse data types.\n\nhead: returns the first few specified rows of a data frame\nst_crs: getting the coordinate system of a SFO\nst_set_crs: set the CRS of a SFO\n\nWhen to use st_transform vs. st_set_crs?\n\nUse st_set_crs when the data lack a CRS or has an incorrect CRS and you want to correct it. It does not change the underlying geometry data in any way, and only changes the representation of it. st_transform assumes that the previous SFO has a valid CRS value. Use st_crs to check the CRS value if you are unsure.\n\n\nplot: plot data using ggplot2\nsummary: function that comes with base R that summarises all sorts of data including data-frames. When applied to a data-frame, it gives a statistical summary of each column, including the mean, median, etc. However, you typically apply it to a column of a data-frame.\ntop_n: function that comes with dplyr which is used to get the top n values of a column in a data-frame given the attribute name. For example, top_n(df, 3, score) gets top 3 items with the highest score. Negate 3 to get the lowest scores. Note that score is an identifier, not a string or a variable.\nlengths: used to get the length of each element of the input. “Length” has a pretty arbitrary meaning, so let’s break it down.\n\nData frame: It will be treated as a list of columns, so the output will be the number of items for each column. It does not get affected by the presence of NA values, it will count them regardless.\n\nst_join: joins two data-frames together\n\nThe difference between this and st_join is that the latter is only designed to be used with spatial data while this works with any data-frame.\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nwrite_rds: save an R object to a file\n\nSimilar to pickle in Python.\n\n\nYou can use the indexing operator to get a particular row of a data frame given the column name.\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling) is equivalent to buffer_cycling[\"AREA\"] = st_area(buffer_cycling) in other languages.\nBackticks are used to allow identifiers which are typically invalid (contain spaces) to be column names, functions, or variables.\n%&gt;% is the piping operator in R, which allows you to compose function chains without nesting functions within each other. It essentially passes the output of the expression on its left-hand side as the first argument to the function on its right-hand side. sum(round(abs(c(-1.5, 2.3, -3.8, 4.2)))) is functionally equivalent to:\nc(-1.5, 2.3, -3.8, 4.2) %&gt;%\n  abs() %&gt;%\n  round() %&gt;%\n  sum()\nLearn more from ggplot2 examples.\n\nplot should be treated as a multi-tool that should be able to plot all sorts of data types.\n\nUse the “environment” tab in RStudio to visualise your data-frames.\nChoropleth maps\n\nUsed to represent geographical areas.\nUsing lines to segment off areas and colours to shade areas depending on its attribute value.\nTypes\n\nClassified\n\nSegments values into range intervals. The intervals are also known as bins.\nIt does not have to be numerical values, it could be categorical too (political parties).\nHow many colours to use?\n\nTry to stay within 8 colours.\nThe generality of the data (the more general it is, the less colour shades you need).\n\nClassification methods (tmap supports all of them)\n\nQuantile\n\nThe number of districts for each value range is kept the same.\n\nEqual interval\n\nThe range between each segment is the same.\nAvoid this when the data is highly skewed.\n\nJenk’s method\n\nA combination of quartile and equal interval methods.\n\nStandard deviation\n\nOnly useful if your data follows a normal distribution.\nInstead of mapping based on actual values, you map based on their z-scores.\n\n\n\nUnclassified\n\nThere are no fixed segmentation for colours. Instead colour values are continous and there is only one interval from the smallest value to the largest value.\n\n\nWhat colours to use?\n\nUse ColorBrewer which is an application to help choose your colour scheme based on your data.\nColour schemes used:\n\nNominal\n\nCategorical data\n\nSequential\n\nEither all positive or negative numbers.\n\nDiverging\n\nUse when the data does not fit the above scenarios.\n\n\n\nBoth types of choropleth maps require you to state the minimum and maximum value and how the colours vary across the spectrum in the legend.\nUsing tmap:\n\ntmap is a thematic mapping package for R.\nIncludes an R implementation of ColorBrewer.\nIt is compatible with the sf package.\nUnder tmap, simple features can be further grouped into spatial and raster types.\nSimple features that contains attributes:\n\nClasses that start with “Spatial” and include the phrase “DataFrame”.\nClasses that start with “Raster”.\n\nSimple features with no attributes:\n\nThe rest.\n\nLike the plot function in the ggplot2 package, we can use the function qtm to quickly plot out our choropleth map.\nThe map can also be interactive if needed using the function tmap_mode.\ntmap_shape: specifies the shape object\n\nTakes a Shapefile or a SFO as input.\nAlso includes a bounding box input to control the zoom level of the map.\n\ntm_polygons: draw polygons\n\nA wrapper of tm_fill and tm_border.\n\ntm_symbols: draw symbols\ntm_lines: draw polylines\ntm_raster: draw a raster\ntm_text: add text labels\nLayers (note that you must call tm_shape first to create the shapes before you can manipulate the shapes with tm_fill, etc.) (use these functions if you want more flexibility for customisation)\n\ntm_fill: fills the polygons\ntm_fill(col=color)\ntm_borders: draws polygon borders\n\nlwd: border line width (default: 1)\nalpha: transparency number between 0 (totally transparent) and 1 (totally opaque) (default: 1)\ncol: border colour\nlty: border line type (default: \"solid\")\n\ntm_bubbles: draws bubbles\ntm_squares: draws squares\ntm_dots: draws dots\ntm_markers: draws markers\ntm_iso: draw iso/contour lines\n\nFurniture\n\ntm_compass: draws a compass\ntm_scale_bar: draws a geographic scale bar\ntm_grid: draws a map grid\n\nWays to create multiple small Choropleth maps (facet maps)\n\nassigning multiple values to at least one of the aesthetic arguments (useful for showing multiple attributes given the same geographical area)\n\ndefining ncols in tm_fill\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\nassigning multiple values to at least one of the aesthetic arguments (useful for showing multiple attributes given the same geographical area)\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\ntm_facets group-by variable (useful for showing multiple geographical areas given the same attribute)\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\nThis groups by \"REGION_N\".\nmultiple standalone maps using tmap_arrange (useful for showing multiple attributes given the same geographical area)\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\nYou can use the selection function to only choose certain geographical areas you want to map out.\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\nIterating over data-frame rows for data wrangling\n\nfilter: filter rows by predicate\npopdata %&gt;% filter(Time == 2020)\ngroup_by: group by columns\n\nIt groups elements by the first field, and then subsequent fields.\nIt does not do any data aggregating.\nSpecifies a scope whereby subsequent queries apply to each group separately. If you no longer want operations to apply for each group but each row, use the ungroup function as a pipe operation.\npopdata %&gt;% group_by(PA, SZ, AG)\n\nsummarise: aggregates rows of data\n\nTypically used in conjunction with group_by which aggregates data based on the last field specified by group_by.\npopdata %&gt;% group_by(PA, SZ, AG) %&gt;%\nsummarise(`POP` = sum(`Pop`))\n\nmutate: a function from dplyr which is extremely versatile and used to modify existing data-frames by accepting a data-frame as an input and outputting a new modified data-frame without modifying the existing one.\n\nCreate new columns:\n# Example data frame\ndf &lt;- data.frame(\n  id = 1:5,\n  height = c(150, 160, 170, 180, 190),  # height in centimeters\n  weight = c(55, 60, 65, 70, 75)        # weight in kilograms\n)\n\n# Use mutate to create a new column 'height_in_meters'\ndf &lt;- df %&gt;%\n  mutate(height_in_meters = height / 100)\nIn-place transformation of data:\nmutate(df, height = height / 100)\nMultiple transformations in a single mutate call:\nmutate(\n    df,\n    bmi = weight / (height_in_meters^2),\n    bmi_category = case_when(\n      bmi &lt; 18.5 ~ \"Underweight\",\n      bmi &gt;= 18.5 & bmi &lt; 24.9 ~ \"Normal weight\",\n      bmi &gt;= 25 & bmi &lt; 29.9 ~ \"Overweight\",\n      TRUE ~ \"Obese\"\n    )\n  )\nrowSums: sums up columns in each row\npopdata %&gt;% mutate(A = rowSums(.[7:11]) + rowSums(.[13:15]))\nRemember that ranges in R are inclusive.\n\npivot_wider: make each unique row be a column\n\nLet’s say a column known as “AG” contain the values \"a\" and \"b\", each one only occurring once. There is also another column named “POP” filled with numbers. This function creates columns “a” and “b” and applies the “POP” value as the value for its respective cells.\n\nselect: only include specific fields\n\nSimilar to the concept of selecting in SQL.\npopdata %&gt;% select(field1, field2)\n\nmutate_at: applies multiple function operations to multiple columns\npopdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper))\nMutate columns “PA” and “SZ” by converting them to uppercase. You can apply multiple different kinds of operations but we are only using one.\n\nMaking Choropleth maps\n\nEasiest way\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\nHarder way (more customisable)\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\nThe style argument specifies the classification method to be used. Here is a list of them:\n\nquantile\nequal (make sure the data is not skewed)\njenks\n\nYou can also manually specify the breakpoints:\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\nThe palette argument specifies the fill colour scheme to be used. Using a - sign before the colour scheme makes the smaller values be represented with darker colour than the greater values, e.g. \"-Greens\".\nBesides colour, you can also specify the style of the map with tmap_style which affects aspects such as the background colour of the map and the font, etc. This is independent of what colour each polygon is filled with.\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\nThe default style is \"white\".\n\n\nAdding additional map complications\n\nHistogram\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\nCompass, scale bar, and grid lines\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))"
  }
]