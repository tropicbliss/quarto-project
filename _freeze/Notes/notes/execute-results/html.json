{
  "hash": "0983678317f0f4c10af73a6113eec6a3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Notes\"\nexecute:\n  freeze: true\n---\n\n\n-   GIS is a software tool to analyse and visualise geographical information, it's not a discipline.\n\n-   Geospatial analysis turns data into information that we can make decisions on.\n\n-   Geospatial data is data stored in a special database that can be thought of as a simplified model of the real world.\n\n-   What is a data-frame?\n\n    -   A data structure organised as a table where data is organised in rows and columns. Each column typically stores data of a single data type. You can think of it as a spreadsheet or a database table. It can be manipulated via operations like filtering or grouping data.\n\n-   Types of geospatial data\n\n    -   Vector\n\n        -   Stores data that are discrete in nature (you can count the total number of data that is representable)\n\n        -   The SVG of geospatial data\n\n        -   Data primitives (simple features)\n\n            -   Points\n\n                -   Coordinate\n\n                -   Examples\n\n                    -   Landmarks\n\n            -   Polyline (line + polygon)\n\n                -   Series of coordinates known as vertices (though like other data types they might also contain additional metadata such as road names)\n\n                -   Examples\n\n                    -   Roads\n\n            -   Polygon\n\n                -   Consists of three or more line segments, and the starting and end coordinates must be the same, but how they are stored is almost the same as how vertices are stored in a polyline.\n\n                -   Buildings\n\n    -   Raster (simple features)\n\n        -   Stores data that are continuous in nature (data that does not have a clear cut off point)\n\n        -   The JPEG of geospatial data\n\n        -   Elevation\n\n        -   The area of interest is divided into cells (which are essentially pixels on the screen). A grid typically only stores a single attribute of the area of interest, and each grid is responsible for a certain real world area size (such as 10x10 metres). The data stored in each grid is fixed. For instance, a grid can store a single 32 bit floating point value.\n\n-   Coordinate system\n\n    -   Coordinates stored in different coordinate systems will have wildly different values relative to each other.\n\n    -   Types\n\n        -   Geographical coordinate systems\n\n            -   Uses a three dimensional system to encode data\n\n                -   Latitude\n\n                    -   Vertical line\n\n                    -   0 degrees at the equator, +90 degrees in the north pole and -90 degrees in the south pole\n\n                -   Longitude\n\n                    -   Horizontal line\n\n                        -   0 degrees at Greenwich\n\n                            -   0 to +180 degrees (east)\n\n                            -   0 to -180 degrees (west)\n\n                -   Datum\n\n                    -   Defines the shape and the size of the earth as the equator or Greenwich while being used as a reference for the coordinate system does not define how much it varies as you stray further away from it.\n\n                    -   Examples\n\n                        -   WGS84\n\n                            -   Defines the earth as an ellipsoid\n\n            -   Not suitable for distance measurement as it takes the curvature of the earth into account which makes it more challenging to calculate. A single degree of difference can lead to different distances depending on the coordinates of the start and end points.\n\n        -   Projected coordinate system\n\n            -   Examples\n\n                -   SVY21 (Singapore) (EPSG code: 3414)\n\n            -   Provides consistent area measurements.\n\n            -   Important to convert from GCS to PCS before conducting analysis.\n\n            -   Large countries might use multiple PCS.\n\n            -   Each country or state might have their own PCS to minimise distortions from projecting a spherical surface into a plane, to create an accurate representation of an area.\n\n            -   Make sure to convert to this form before doing any analysis.\n\n-   Simple features\n\n    -   There are about 17 of them, 3 of them having been mentioned above.\n\n    -   Most software typically only use a subset of them.\n\n    -   Types\n\n        -   Point\n\n            -   `Point(30, 10)`\n\n        -   Multi point\n\n            -   `MultiPoint([Point(10, 40), Point(40, 30), Point(20, 20), Point(30, 10)])`\n\n        -   Line string\n\n            -   `LineString([Point(30, 10), Point(10, 30), Point(40, 40)])`\n\n        -   Polygon\n\n            -   `Polygon([Point(30, 10), Point(40, 40), Point(20, 40), Point(10, 20), Point(30, 10)])`\n\n            -   `Polygon([[Point(35, 10), Point(45, 45), Point(15, 40), Point(10, 20), Point(35, 10)], [Point(20, 30), Point(35, 35), Point(30, 20), Point(20, 30)]])`\n\n        -   MultiX\n\n            -   \"Multi\" versions of the above primitives but have them be elements of an array.\n\n    -   To work with simple features, you can use the `sf` package from R which is part of the `tidyverse` collection.\n\n    -   Simple features are represented via \"simple features geometry (SFG)\", and they and geospatial data can be represented with \"simple features objects (SFO)\" which represent a collection of SFG as a data-frame object. The non-spatial data (metadata) are stored in a separate column separate from the SFG column. The data type of that SFG column is known as \"simple features collection (SFC)\".\n\n-   `sf` functions\n\n    -   `sf` also provides functions that help you in doing data manipulation and analysis of spatial data.\n\n    -   `st_read`: import a file or database into a SFO (more flexible but slower)\n\n        -   `read_sf`: import a file or database into a SFO (less flexible but more optimised)\n\n        -   Shapefiles can contain many layers, such as elevation that shows different data on the same geography. Each layer can have multiple attributes.\n\n        -   Supported file formats\n\n            -   Shapefile\n\n                -   A misnomer as it is basically a collection of files (hence a single `shp` file is not enough). File extensions include: `dbf`, `prj`, `shp`, `xml`, and `shx`.\n\n                    ```         \n                    sf_mpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE\")\n                    st_write(st_poly, \"data/my_poly.shp\")\n                    ```\n\n            -   MapInfo TAB\n\n            -   KML (Google)\n\n                ```         \n                sf_preschool = st_read(\"data/geospatial/pre-schools-location-kml.kml\")\n                ```\n\n                You need to provide the file extension if it is not a Shapefile.\n\n            -   GML\n\n            -   GeoJSON (popular in web)\n\n            -   TopoJSON (popular in web)\n\n    -   `st_write`: export a file from a SFO to a file or database\n\n        -   `write_sf`: export a file from a SFO to a file or database (less flexible but more optimised)\n\n    -   `st_as_sf`: convert existing data structures into a SFO\n\n    -   `st_as_text`: convert a SFO into \"well-known text\" (WKT) (it is the `to_string()` of SFO and represents the SFO data structure in a textual format)\n\n    -   `st_as_binary`: converts a SFO into a binary format\n\n    -   `st_transform`: Convert a SFO into another SFO with a different coordinate reference system via an EPSG code. For example, it can convert GCS data to PCS.\n\n        -   A coordinate reference system is a system that specifies the datum (among other attributes) of the coordinate system. It can be represented as a numerical code known as the EPSG code.\n\n    -   `st_intersects`: whether two geometries touch or overlap each other\n\n        -   Note that many `sf` functions may sound similar to each other but perform totally different tasks. For instance, `st_intersects` checks whether each geometry in each SFO intersects with each other while `st_intersection` will create new geometry that shows the areas of intersection.\n\n        -   Many other functions in this category work the same way, and they all typically return a sparse list.\n\n        -   Sparse lists\n\n            -   A sparse list is a way of efficiently representing the relationship of a geometry in one set with respect to another geometry in another set without using a full matrix.\n\n            -   Using `st_intersects`:\n\n                ```         \n                # Example sparse list\n                result <- list(\n                  c(2, 3),\n                  integer(0),\n                  c(1, 4)\n                )\n                ```\n\n                -   `result[[1]]` (First Geometry in `A`):\n\n                    -   The first element `c(2, 3)` means that the first geometry in `A` intersects with the 2nd and 3rd geometries in `B`.\n\n                -   `result[[2]]` (Second Geometry in `A`):\n\n                    -   The second element `integer(0)` (an empty integer vector) means that the second geometry in `A` does not intersect with any geometry in `B`.\n\n                -   `result[[3]]` (Third Geometry in `A`):\n\n                    -   The third element `c(1, 4)` means that the third geometry in `A` intersects with the 1st and 4th geometries in `B`.\n\n                -   Note that sparse lists do not include symmetric pairs, e.g., `(2, 4` and `(4, 2)` are repeated.\n\n    -   Functions that return a logical matrix indicating whether each geometry pair meets the logical operation\n\n        -   `st_disjoint`: equivalent to performing a NOT boolean operation on the result of `st_intersects`\n\n        -   `st_touches`: touch\n\n        -   `st_crosses`: cross\n\n        -   `st_within`: within\n\n        -   `st_contains`: overlap\n\n        -   `st_overlaps`: overlaps\n\n        -   `st_covers`: cover\n\n        -   `st_covered_by`: covered by\n\n        -   `st_equals`: equals\n\n        -   `st_equals_exact`: equals, with some fuzz\n\n            -   Returns a sparse (default) or dense logical matrix.\n\n    -   Geometry generating logical operators:\n\n        -   `st_union`: union of several geometries\n\n        -   `st_intersection`: intersection of pairs of geometries\n\n        -   `st_difference`: difference between pairs of geometries\n\n            -   If `st_difference(A, B)`, take `A` and subtract any areas of overlap by `B`.\n\n        -   `st_sym_difference`: symmetric difference (XOR)\n\n            -   Equivalent to `st_union(st_difference(A, B), st_difference(B, A))`.\n\n    -   Other miscellaneous functions:\n\n        -   `st_area` calculates the area of the geometries of the SFO given to it as a parameter and outputs a data-frame column.\n\n            -   For example, to calculate the area of each geometry, you can do:\n\n                ```         \n                sfo$Area <- sfo %>% st_area()\n                ```\n\n        -   `sum` is an aggregation function that takes in a data-frame column and returns a number.\n\n    -   Higher level operations\n\n        -   `aggregate`\n\n        -   `summarise`\n\n        -   `st_interpolate_aw`: area-weighted interpolation of attributes from one set of geometries to another\n\n            -   Area-weighted interpolation is a spatial analysis technique used to estimate or transfer values from one set of spatial units (e.g., polygons) to another set of spatial units that may overlap or have different boundaries. For instance, you might have census tracts for population and want to map out the population of each district. The census tract does not match the district. Hence, you will want to use this function to transfer population data over.\n\n            -   You need to specify the source and target geometries, each of which are SFOs, but the target geometry does not need to have any attributes. You also need to specify whether the interpolation is done extensively or intensively.\n\n            -   In extensive interpolation, you need to sum the contributions from each source polygon based on the proportion of its area that overlaps with the target polygon. For example, if you have a source polygon with a population of 1000 people and it overlaps by 50% with a target polygon, the area-weighted interpolation would allocate 500 people to the target polygon.\n\n            -   Intensive attributes are those that are independent of the size or extent of the spatial unit they are associated with. These attributes describe a characteristic that does not change when you change the size of the area. An example of an intensive attribute is population density. For example, if one source polygon has a population density of 200 people per square kilometer and overlaps by 50% with a target polygon, and another source polygon has a density of 100 people per square kilometer and overlaps by 50%, the resulting population density in the target polygon would be the weighted average of these densities.\n\n        -   `st_join`: performs spatial joins between two SFOs\n\n            -   A spatial join merges attributes from one SFO to another.\n\n            -   The output SFO will retain the geometries of the first input SFO.\n\n            -   Think of the second input SFO as an overlay for the first SFO.\n\n                [![Illustration of st_join](https://r-spatial.github.io/sf/reference/st_join-1.png)](https://r-spatial.github.io/sf/reference/st_join.html)\n\n                Observe that `st_join` does not do any interpolation or any mathematical operations. It also does not include any points in `b`. Any repeating data from the merge is included in the final output as an additional row.\n\n\n                ::: {.cell}\n                \n                ```{.r .cell-code}\n                pacman::p_load(sf)\n                a = st_sf(a = 1:3,\n                 geom = st_sfc(st_point(c(1,1)), st_point(c(2,2)), st_point(c(3,3))))\n                b = st_sf(a = 11:15,\n                 geom = st_sfc(st_point(c(10,10)), st_point(c(2,2)), st_point(c(2,2)), st_point(c(3,3)), st_point(c(12,12))))\n                st_join(a, b)\n                ```\n                \n                ::: {.cell-output .cell-output-stdout}\n                \n                ```\n                Simple feature collection with 4 features and 2 fields\n                Geometry type: POINT\n                Dimension:     XY\n                Bounding box:  xmin: 1 ymin: 1 xmax: 3 ymax: 3\n                CRS:           NA\n                    a.x a.y        geom\n                1     1  NA POINT (1 1)\n                2     2  12 POINT (2 2)\n                2.1   2  13 POINT (2 2)\n                3     3  14 POINT (3 3)\n                ```\n                \n                \n                :::\n                :::\n\n\n    -   Manipulating geometries (spatial data wrangling) (generates new data out of existing data) (the output SFC does not contain any input data)\n\n        -   `st_line_merge`: merges lines\n\n        -   `st_segmentize`: adds points to straight lines\n\n        -   `st_voronoi`: creates voronoi tesselation\n\n        -   `st_centroid`: gives centroid of geometry\n\n            -   Outputs a SFC containing points corresponding to the centre of each geometry.\n\n        -   `st_convex_hull`: creates convex hull of set of points\n\n        -   `st_triangulate`: triangulates sets of points (not constrained)\n\n        -   `st_polygonize`: creates polygon from lines that form a closed ring\n\n        -   `st_simplify`: simplifies lines by removing vertices\n\n        -   `st_split`: split a polygon given line boundary\n\n        -   `st_buffer`: compute a buffer around this geometry/each geometry\n\n            -   Takes an SFO as input.\n\n            -   Creates a region that expands outwards from each geometry by a given distance, creating a buffer zone.\n\n            -   For points, it creates a circular buffer. For lines, it creates a buffer along the entire length of the line, creating a polygon that surrounds the line. For polygons, it expands the polygon by a given distance, keeping it's shape, resulting in a scaled up version of the original polygon.\n\n            -   Returns a SFC containing only the buffer.\n\n            -   Uses the unit of measurement specified by the PCS, e.g., SVY21 (Singapore) uses metres as the unit of measurement.\n\n            -   `nQuadSegs` determine the smoothness of the circular arcs that make up the buffer. The more the number of quad segments the smoother the curve. It's typically sufficient to leave this as the default.\n\n        -   `st_make_valid`: tries to make an invalid geometry valid (requires `lwgeom`)\n\n        -   `st_boundary`: returns the boundary of a geometry\n\n    -   Convenience functions\n\n        -   `st_zm`: sets or removes z and/or m geometry\n\n        -   `st_coordinates`: retrieves coordinates in a matrix or data frame\n\n        -   `st_geometry`: sets, or retrieves SFC from an SFO\n\n            -   Returns the SFC.\n\n        -   `st_is`: checks whether a geometry is of a particular type\n\n-   Other functions\n\n    -   `glimpse`: part of the `dplyr` package\n\n        -   Used to analyse any R object, but especially useful for `tidyverse` data types.\n\n    -   `head`: returns the first few specified rows of a data frame\n\n    -   `st_crs`: getting the coordinate system of a SFO\n\n    -   `st_set_crs`: set the CRS of a SFO\n\n        -   When to use `st_transform` vs. `st_set_crs`?\n\n            -   Use `st_set_crs` when the data lack a CRS or has an incorrect CRS and you want to correct it. It does not change the underlying geometry data in any way, and only changes the representation of it. `st_transform` assumes that the previous SFO has a valid CRS value. Use `st_crs` to check the CRS value if you are unsure.\n\n    -   `plot`: plot data using `ggplot2`\n\n    -   `summary`: function that comes with base R that summarises all sorts of data including data-frames. When applied to a data-frame, it gives a statistical summary of each column, including the mean, median, etc. However, you typically apply it to a column of a data-frame.\n\n    -   `top_n`: function that comes with `dplyr` which is used to get the top n values of a column in a data-frame given the attribute name. For example, `top_n(df, 3, score)` gets top 3 items with the highest score. Negate 3 to get the lowest scores. Note that `score` is an identifier, not a string or a variable.\n\n    -   `lengths`: used to get the length of each element of the input. \"Length\" has a pretty arbitrary meaning, so let's break it down.\n\n        -   Data frame: It will be treated as a list of columns, so the output will be the number of items for each column. It does not get affected by the presence of `NA` values, it will count them regardless.\n\n    -   `st_join`: joins two data-frames together\n\n        -   The difference between this and `st_join` is that the latter is only designed to be used with spatial data while this works with any data-frame.\n\n            ```         \n            mpsz_pop2020 <- left_join(mpsz, popdata2020,\n                                      by = c(\"SUBZONE_N\" = \"SZ\"))\n            ```\n\n    -   `write_rds`: save an R object to a file\n\n        -   Similar to `pickle` in Python.\n\n-   You can use the indexing operator to get a particular row of a data frame given the column name.\n\n-   `buffer_cycling$AREA <- st_area(buffer_cycling)` is equivalent to `buffer_cycling[\"AREA\"] = st_area(buffer_cycling)` in other languages.\n\n-   Backticks are used to allow identifiers which are typically invalid (contain spaces) to be column names, functions, or variables.\n\n-   `%>%` is the piping operator in R, which allows you to compose function chains without nesting functions within each other. It essentially passes the output of the expression on its left-hand side as the first argument to the function on its right-hand side. `sum(round(abs(c(-1.5, 2.3, -3.8, 4.2))))` is functionally equivalent to:\n\n    ```         \n    c(-1.5, 2.3, -3.8, 4.2) %>%\n      abs() %>%\n      round() %>%\n      sum()\n    ```\n\n-   Learn more from `ggplot2` examples.\n\n    -   `plot` should be treated as a multi-tool that should be able to plot all sorts of data types.\n\n-   Use the \"environment\" tab in RStudio to visualise your data-frames.\n\n-   Choropleth maps\n\n    -   Used to represent geographical areas.\n\n    -   Using lines to segment off areas and colours to shade areas depending on its attribute value.\n\n    -   Types\n\n        -   Classified\n\n            -   Segments values into range intervals. The intervals are also known as bins.\n\n            -   It does not have to be numerical values, it could be categorical too (political parties).\n\n            -   How many colours to use?\n\n                -   Try to stay within 8 colours.\n\n                -   The generality of the data (the more general it is, the less colour shades you need).\n\n            -   Classification methods (`tmap` supports all of them)\n\n                -   Quantile\n\n                    -   The number of districts for each value range is kept the same.\n\n                -   Equal interval\n\n                    -   The range between each segment is the same.\n\n                    -   Avoid this when the data is highly skewed.\n\n                -   Jenk's method\n\n                    -   A combination of quartile and equal interval methods.\n\n                -   Standard deviation\n\n                    -   Only useful if your data follows a normal distribution.\n\n                    -   Instead of mapping based on actual values, you map based on their z-scores.\n\n        -   Unclassified\n\n            -   There are no fixed segmentation for colours. Instead colour values are continous and there is only one interval from the smallest value to the largest value.\n\n    -   What colours to use?\n\n        -   Use ColorBrewer which is an application to help choose your colour scheme based on your data.\n\n        -   Colour schemes used:\n\n            -   Nominal\n\n                -   Categorical data\n\n            -   Sequential\n\n                -   Either all positive or negative numbers.\n\n            -   Diverging\n\n                -   Use when the data does not fit the above scenarios.\n\n    -   Both types of choropleth maps require you to state the minimum and maximum value and how the colours vary across the spectrum in the legend.\n\n    -   Using `tmap`:\n\n        -   `tmap` is a thematic mapping package for R.\n\n        -   Includes an R implementation of ColorBrewer.\n\n        -   It is compatible with the `sf` package.\n\n        -   Under `tmap`, simple features can be further grouped into spatial and raster types.\n\n        -   Simple features that contains attributes:\n\n            -   Classes that start with \"Spatial\" and include the phrase \"DataFrame\".\n\n            -   Classes that start with \"Raster\".\n\n        -   Simple features with no attributes:\n\n            -   The rest.\n\n        -   Like the `plot` function in the `ggplot2` package, we can use the function `qtm` to quickly plot out our choropleth map.\n\n        -   The map can also be interactive if needed using the function `tmap_mode`.\n\n        -   `tmap_shape`: specifies the shape object\n\n            -   Takes a Shapefile or a SFO as input.\n\n            -   Also includes a bounding box input to control the zoom level of the map.\n\n        -   `tm_polygons`: draw polygons\n\n            -   A wrapper of `tm_fill` and `tm_border`.\n\n        -   `tm_symbols`: draw symbols\n\n        -   `tm_lines`: draw polylines\n\n        -   `tm_raster`: draw a raster\n\n        -   `tm_text`: add text labels\n\n        -   Layers (note that you must call `tm_shape` first to create the shapes before you can manipulate the shapes with `tm_fill`, etc.) (use these functions if you want more flexibility for customisation)\n\n            -   `tm_fill`: fills the polygons\n\n                ```         \n                tm_fill(col=color)\n                ```\n\n            -   `tm_borders`: draws polygon borders\n\n                -   `lwd`: border line width (default: `1`)\n\n                -   `alpha`: transparency number between 0 (totally transparent) and 1 (totally opaque) (default: `1`)\n\n                -   `col`: border colour\n\n                -   `lty`: border line type (default: `\"solid\"`)\n\n            -   `tm_bubbles`: draws bubbles\n\n            -   `tm_squares`: draws squares\n\n            -   `tm_dots`: draws dots\n\n            -   `tm_markers`: draws markers\n\n            -   `tm_iso`: draw iso/contour lines\n\n        -   Furniture\n\n            -   `tm_compass`: draws a compass\n\n            -   `tm_scale_bar`: draws a geographic scale bar\n\n            -   `tm_grid`: draws a map grid\n\n        -   Ways to create multiple small Choropleth maps (facet maps)\n\n            -   assigning multiple values to at least one of the aesthetic arguments (useful for showing multiple attributes given the same geographical area)\n\n                -   defining `ncols` in `tm_fill`\n\n                    ```         \n                    tm_shape(mpsz_pop2020)+\n                      tm_fill(c(\"YOUNG\", \"AGED\"),\n                              style = \"equal\", \n                              palette = \"Blues\") +\n                      tm_layout(legend.position = c(\"right\", \"bottom\")) +\n                      tm_borders(alpha = 0.5) +\n                      tmap_style(\"white\")\n                    ```\n\n            -   assigning multiple values to at least one of the aesthetic arguments (useful for showing multiple attributes given the same geographical area)\n\n                ```         \n                tm_shape(mpsz_pop2020)+ \n                  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n                          style = c(\"equal\", \"quantile\"), \n                          palette = list(\"Blues\",\"Greens\")) +\n                  tm_layout(legend.position = c(\"right\", \"bottom\"))\n                ```\n\n            -   `tm_facets` group-by variable (useful for showing multiple geographical areas given the same attribute)\n\n                ```         \n                tm_shape(mpsz_pop2020) +\n                  tm_fill(\"DEPENDENCY\",\n                          style = \"quantile\",\n                          palette = \"Blues\",\n                          thres.poly = 0) + \n                  tm_facets(by=\"REGION_N\", \n                            free.coords=TRUE, \n                            drop.shapes=TRUE) +\n                  tm_layout(legend.show = FALSE,\n                            title.position = c(\"center\", \"center\"), \n                            title.size = 20) +\n                  tm_borders(alpha = 0.5)\n                ```\n\n                This groups by `\"REGION_N\"`.\n\n            -   multiple standalone maps using `tmap_arrange` (useful for showing multiple attributes given the same geographical area)\n\n                ```         \n                youngmap <- tm_shape(mpsz_pop2020)+ \n                  tm_polygons(\"YOUNG\", \n                              style = \"quantile\", \n                              palette = \"Blues\")\n\n                agedmap <- tm_shape(mpsz_pop2020)+ \n                  tm_polygons(\"AGED\", \n                              style = \"quantile\", \n                              palette = \"Blues\")\n\n                tmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n                ```\n\n        -   You can use the selection function to only choose certain geographical areas you want to map out.\n\n            ```         \n            tm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n              tm_fill(\"DEPENDENCY\", \n                      style = \"quantile\", \n                      palette = \"Blues\", \n                      legend.hist = TRUE, \n                      legend.is.portrait = TRUE,\n                      legend.hist.z = 0.1) +\n              tm_layout(legend.outside = TRUE,\n                        legend.height = 0.45, \n                        legend.width = 5.0,\n                        legend.position = c(\"right\", \"bottom\"),\n                        frame = FALSE) +\n              tm_borders(alpha = 0.5)\n            ```\n\n-   Iterating over data-frame rows for data wrangling\n\n    -   `filter`: filter rows by predicate\n\n        ```         \n        popdata %>% filter(Time == 2020)\n        ```\n\n    -   `group_by`: group by columns\n\n        -   It groups elements by the first field, and then subsequent fields.\n\n        -   It does not do any data aggregating.\n\n        -   Specifies a scope whereby subsequent queries apply to each group separately. If you no longer want operations to apply for each group but each row, use the `ungroup` function as a pipe operation.\n\n            ```         \n            popdata %>% group_by(PA, SZ, AG)\n            ```\n\n    -   `summarise`: aggregates rows of data\n\n        -   Typically used in conjunction with `group_by` which aggregates data based on the last field specified by `group_by`.\n\n            ```         \n            popdata %>% group_by(PA, SZ, AG) %>%\n            summarise(`POP` = sum(`Pop`))\n            ```\n\n    -   `mutate`: a function from `dplyr` which is extremely versatile and used to modify existing data-frames by accepting a data-frame as an input and outputting a new modified data-frame without modifying the existing one.\n\n        -   Create new columns:\n\n            ```         \n            # Example data frame\n            df <- data.frame(\n              id = 1:5,\n              height = c(150, 160, 170, 180, 190),  # height in centimeters\n              weight = c(55, 60, 65, 70, 75)        # weight in kilograms\n            )\n\n            # Use mutate to create a new column 'height_in_meters'\n            df <- df %>%\n              mutate(height_in_meters = height / 100)\n            ```\n\n        -   In-place transformation of data:\n\n            ```         \n            mutate(df, height = height / 100)\n            ```\n\n        -   Multiple transformations in a single mutate call:\n\n            ```         \n            mutate(\n                df,\n                bmi = weight / (height_in_meters^2),\n                bmi_category = case_when(\n                  bmi < 18.5 ~ \"Underweight\",\n                  bmi >= 18.5 & bmi < 24.9 ~ \"Normal weight\",\n                  bmi >= 25 & bmi < 29.9 ~ \"Overweight\",\n                  TRUE ~ \"Obese\"\n                )\n              )\n            ```\n\n        -   `rowSums`: sums up columns in each row\n\n            ```         \n            popdata %>% mutate(A = rowSums(.[7:11]) + rowSums(.[13:15]))\n            ```\n\n            Remember that ranges in R are inclusive.\n\n    -   `pivot_wider`: make each unique row be a column\n\n        -   Let's say a column known as \"AG\" contain the values `\"a\"` and `\"b\"`, each one only occurring once. There is also another column named \"POP\" filled with numbers. This function creates columns \"a\" and \"b\" and applies the \"POP\" value as the value for its respective cells.\n\n    -   `select`: only include specific fields\n\n        -   Similar to the concept of selecting in SQL.\n\n            ```         \n            popdata %>% select(field1, field2)\n            ```\n\n    -   `mutate_at`: applies multiple function operations to multiple columns\n\n        ```         \n        popdata2020 %>%\n          mutate_at(.vars = vars(PA, SZ), \n                  .funs = list(toupper))\n        ```\n\n        Mutate columns \"PA\" and \"SZ\" by converting them to uppercase. You can apply multiple different kinds of operations but we are only using one.\n\n-   Making Choropleth maps\n\n    -   Easiest way\n\n        ```         \n        tmap_mode(\"plot\")\n        qtm(mpsz_pop2020, \n            fill = \"DEPENDENCY\")\n        ```\n\n        -   Harder way (more customisable)\n\n            ```         \n            tm_shape(mpsz_pop2020)+\n              tm_fill(\"DEPENDENCY\", \n                      style = \"quantile\", \n                      palette = \"Blues\",\n                      title = \"Dependency ratio\") +\n              tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n                        main.title.position = \"center\",\n                        main.title.size = 1.2,\n                        legend.height = 0.45, \n                        legend.width = 0.35,\n                        frame = TRUE) +\n              tm_borders(alpha = 0.5) +\n              tm_compass(type=\"8star\", size = 2) +\n              tm_scale_bar() +\n              tm_grid(alpha =0.2) +\n              tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n                         position = c(\"left\", \"bottom\"))\n            ```\n\n            The `style` argument specifies the classification method to be used. Here is a list of them:\n\n            -   `quantile`\n\n            -   `equal` (make sure the data is not skewed)\n\n            -   `jenks`\n\n            You can also manually specify the breakpoints:\n\n            ```         \n            tm_shape(mpsz_pop2020)+\n              tm_fill(\"DEPENDENCY\",\n                      breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n              tm_borders(alpha = 0.5)\n            ```\n\n            The `palette` argument specifies the fill colour scheme to be used. Using a `-` sign before the colour scheme makes the smaller values be represented with darker colour than the greater values, e.g. `\"-Greens\"`.\n\n            Besides colour, you can also specify the style of the map with `tmap_style` which affects aspects such as the background colour of the map and the font, etc. This is independent of what colour each polygon is filled with.\n\n            ```         \n            tm_shape(mpsz_pop2020)+\n              tm_fill(\"DEPENDENCY\", \n                      style = \"quantile\", \n                      palette = \"-Greens\") +\n              tm_borders(alpha = 0.5) +\n              tmap_style(\"classic\")\n            ```\n\n            The default style is `\"white\"`.\n\n-   Adding additional map complications\n\n    -   Histogram\n\n        ```         \n        tm_shape(mpsz_pop2020)+\n          tm_fill(\"DEPENDENCY\", \n                  style = \"jenks\", \n                  palette = \"Blues\", \n                  legend.hist = TRUE, \n                  legend.is.portrait = TRUE,\n                  legend.hist.z = 0.1) +\n          tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n                    main.title.position = \"center\",\n                    main.title.size = 1,\n                    legend.height = 0.45, \n                    legend.width = 0.35,\n                    legend.outside = FALSE,\n                    legend.position = c(\"right\", \"bottom\"),\n                    frame = FALSE) +\n          tm_borders(alpha = 0.5)\n        ```\n\n    -   Compass, scale bar, and grid lines\n\n        ```         \n        tm_shape(mpsz_pop2020)+\n          tm_fill(\"DEPENDENCY\", \n                  style = \"quantile\", \n                  palette = \"Blues\",\n                  title = \"No. of persons\") +\n          tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n                    main.title.position = \"center\",\n                    main.title.size = 1.2,\n                    legend.height = 0.45, \n                    legend.width = 0.35,\n                    frame = TRUE) +\n          tm_borders(alpha = 0.5) +\n          tm_compass(type=\"8star\", size = 2) +\n          tm_scale_bar(width = 0.15) +\n          tm_grid(lwd = 0.1, alpha = 0.2) +\n          tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n                     position = c(\"left\", \"bottom\"))\n        ```\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}